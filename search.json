[
  {
    "objectID": "r_tidyverse_clean_wrangle.html",
    "href": "r_tidyverse_clean_wrangle.html",
    "title": "Cleaning and Wrangling Data",
    "section": "",
    "text": "TipLearning Objectives\n\n\n\n\nIntroduce dplyr and tidyr functions to clean and wrangle data for analysis\nLearn about the Split-Apply-Combine strategy and how it applies to data wrangling\nDescribe the difference between wide vs. long table formats and how to convert between them",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "r_tidyverse_clean_wrangle.html#introduction",
    "href": "r_tidyverse_clean_wrangle.html#introduction",
    "title": "Cleaning and Wrangling Data",
    "section": "1 Introduction",
    "text": "1 Introduction\nThe data we get to work with are rarely, if ever, in the format we need to do our analyses. It’s often the case that one package requires data in one format, while another package requires the data to be in another format. To be efficient analysts, we should have good tools for reformatting data for our needs so we can do further work like making plots and fitting models. The dplyr and tidyr R packages provide a fairly complete and extremely powerful set of functions for us to do this reformatting quickly. Learning these tools well will greatly increase your efficiency as an analyst.\nLet’s look at two motivating examples.\n\n\n\n\n\n\nNoteExample 1\n\n\n\nSuppose you have the following data.frame called length_data with data about salmon length and want to calculate the average length per year.\n\n\n\nyear\nlength_cm\n\n\n\n\n1990\n5.673318\n\n\n1991\n3.081224\n\n\n1991\n4.592696\n\n\n1992\n4.381523\n\n\n1992\n5.597777\n\n\n1992\n4.900052\n\n\n\nBefore thinking about the code, let’s think about the steps we need to take to get to the answer (aka pseudocode).\nNow, how would we code this? The dplyr R library provides a fast and powerful way to do this calculation in a few lines of code:\n\n\nAnswer\nlength_data %&gt;% \n  group_by(year) %&gt;% \n  summarize(mean_length_cm = mean(length_cm))\n\n\n\n\n\n\n\n\n\n\nNoteExample 2\n\n\n\nAnother process we often need to do is to “reshape” our data. Consider the following table that is in what we call “wide” format:\n\n\n\nsite\n1990\n1991\n…\n1993\n\n\n\n\ngold\n100\n118\n…\n112\n\n\nlake\n100\n118\n…\n112\n\n\n…\n…\n…\n…\n…\n\n\ndredge\n100\n118\n…\n112\n\n\n\nYou are probably familiar with data in the above format, where values of the variable being observed are spread out across columns. In this example we have a different column per year. This wide format works well for data entry and sometimes works well for analysis but we quickly outgrow it when using R (and know it is not tidy data!). For example, how would you fit a model with year as a predictor variable? In an ideal world, we’d be able to just run lm(length ~ year). But this won’t work on our wide data because lm() needs length and year to be columns in our table.\nWhat steps would you take to get this data frame in a long format?\nThe tidyr package allows us to quickly switch between wide format and long format using the pivot_longer() function:\n\n\nAnswer\nsite_data %&gt;% \n  pivot_longer(-site, \n               names_to = \"year\", \n               values_to = \"length\")\n\n\n\n\n\nsite\nyear\nlength\n\n\n\n\ngold\n1990\n101\n\n\nlake\n1990\n104\n\n\ndredge\n1990\n144\n\n\n…\n…\n…\n\n\ndredge\n1993\n145\n\n\n\n\n\nThis lesson will cover examples to learn about the functions you’ll most commonly use from the dplyr and tidyr packages:\n\nCommon dplyr functions\n\n\n\n\n\n\nFunction name\nDescription\n\n\n\n\nmutate()\nCreates modify and deletes columns\n\n\ngroup_by()\nGroups data by one or more variables\n\n\nsummarise()\nSummaries each group down to one row\n\n\nselect()\nKeep or drop columns using their names\n\n\nfilter()\nKeeps rows that matches conditions\n\n\narrange()\norder rows using columns variable\n\n\nrename()\nRename a column\n\n\n\n\nCommon tidyr functions\n\n\n\n\n\n\nFunction name\nDescription\n\n\n\n\npivot_longer()\ntransforms data from a wide to a long format\n\n\npivot_wider()\ntransforms data from a long to a wide format\n\n\nunite()\nUnite multiple columns into one by pasting strings together\n\n\nseparate()\nSeparate a character column into multiple columns with a regular expression or numeric locations",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "r_tidyverse_clean_wrangle.html#data-cleaning-basics",
    "href": "r_tidyverse_clean_wrangle.html#data-cleaning-basics",
    "title": "Cleaning and Wrangling Data",
    "section": "2 Data cleaning basics",
    "text": "2 Data cleaning basics\nTo demonstrate, we’ll be working with a tidied up version of a data set from Alaska Department of Fish & Game containing commercial catch data from 1878-1997. The data set and reference to the original source can be found at its public archive.\n\n\n\n\n\n\nTipSetup\n\n\n\nFirst, open a new Quarto document. Delete everything below the setup chunk, and add a library chunk that calls dplyr, tidyr, and readr\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(readr)\n\n\n\n\n\n\n\n\n\nImportantA note on loading packages\n\n\n\nYou may have noticed the following messages pop up when you ran your library chunk.\nAttaching package: ‘dplyr’\n\nThe following objects are masked from ‘package:stats’:\n\n    filter, lag\n\nThe following objects are masked from ‘package:base’:\n\n    intersect, setdiff, setequal, union\nThese are important messages. They are letting you know that certain functions from the stats and base packages (which are loaded by default when you start R) are masked by different functions with the same name in the dplyr package. It turns out, the order that you load the packages in matters. Since we loaded dplyr after stats, R will assume that if you call filter(), you mean the dplyr version unless you specify otherwise.\nBeing specific about which version of filter(), for example, you call is easy. To explicitly call a function by its unambiguous name, we use the syntax package_name::function_name(...). So, if we wanted to call the stats version of filter() in this Rmarkdown document, I would use the syntax stats::filter(...).\n\n\n\n\n\n\n\n\nCautionRemove messages and warnings\n\n\n\nMessages and warnings are important, but we might not want them in our final document. After you have read the packages in, adjust the chunk settings in your library chunk to suppress warnings and messages by adding #| message: false or #| warning: false. Both of these chunk options, when set to false, prevents messages or warnings from appearing in the rendered file.\n\n\nNow that we have introduced some data wrangling libraries, let’s get the data that we are going to use for this lesson.\n\n\n\n\n\n\nTipSetup\n\n\n\n\nGo to KNB Data Package Alaska commercial salmon catches by management region (1886- 1997)\nFind the data file df35b.302.1. Right click the “Download” button and select “Copy Link Address”\nPaste the copied URL into the read_csv() function\n\nThe code chunk you use to read in the data should look something like this:\n\ncatch_original &lt;- read_csv(\"https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1\")\n\nNote for Windows users: Keep in mind, if you want to replicate this workflow in your local computer you also need to use the url() function here with the argument method = \"libcurl\".\nIt would look like this:\n\ncatch_original &lt;- read.csv(url(\"https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1\", method = \"libcurl\"))\n\n\n\nThis data set is relatively clean and easy to interpret as-is. While it may be clean, it’s in a shape that makes it hard to use for some types of analyses so we’ll want to fix that first.\n\n\n\n\n\n\nNoteExercise\n\n\n\nBefore we get too much further, spend a minute or two outlining your Quarto document so that it includes the following sections and steps:\n\nData Sources\n\nRead in the data\nExplore data\n\nClean and Reshape data\n\nUsing select() function\nCheck column types\nReplace values in a column with mutate()\nReshape data with pivot_longer() and pivot_wider()\nRename columns rename()\nAdd columns with mutate()\nSummary stats using group_by() and summarize()\nFiltering rows using filter()\nSort data using arrange()\nSplit and combine values in columns with separate() and unite()",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "r_tidyverse_clean_wrangle.html#data-exploration",
    "href": "r_tidyverse_clean_wrangle.html#data-exploration",
    "title": "Cleaning and Wrangling Data",
    "section": "3 Data exploration",
    "text": "3 Data exploration\nSimilar to what we did in our Literate Analysis lesson, it is good practice to skim through the data you just read in.\nDoing so is important to make sure the data is read as you were expecting and to familiarize yourself with the data.\nSome of the basic ways to explore your data are:\n\n## Prints the column names of my data frame\ncolnames(catch_original)\n\n## First 6 lines of the data frame\nhead(catch_original)\n\n## Summary of each column of data\nsummary(catch_original)\n\n## Prints unique values in a column (in this case, the region)\nunique(catch_original$Region)\n\n## Opens data frame in its own tab to see each row and column of the data (do in console)\nView(catch_original)",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "r_tidyverse_clean_wrangle.html#about-the-pipe-operator",
    "href": "r_tidyverse_clean_wrangle.html#about-the-pipe-operator",
    "title": "Cleaning and Wrangling Data",
    "section": "4 About the pipe (%>%) operator",
    "text": "4 About the pipe (%&gt;%) operator\nBefore we jump into learning tidyr and dplyr, we first need to explain the pipeline operator %&gt;%.\nBoth the tidyr and the dplyr packages use the pipe operator (%&gt;%), which may look unfamiliar. The pipe is a powerful way to efficiently chain together operations. The pipe will take the output of a previous statement, and use it as the input to the next statement.\nSay you want to both filter() out rows of a data set, and select() certain columns.\nInstead of writing:\n\ndf_filtered &lt;- filter(df, ...)\ndf_selected &lt;- select(df_filtered, ...)\n\nYou can write:\n\ndf_cleaned &lt;- df %&gt;% \n    filter(...) %&gt;%\n    select(...)\n\nIf you think of the assignment operator (&lt;-) as reading like “gets”, then the pipe operator would read like “then”.\nSo you might think of the above chunk being translated as:\n\nThe cleaned data frame gets the original data, and then a filter (of the original data), and then a select (of the filtered data).\n\nThe benefits to using pipes are that you don’t have to keep track of (or overwrite) intermediate data frames. The drawbacks are that it can be more difficult to explain the reasoning behind each step, especially when many operations are chained together. It is good to strike a balance between writing efficient code (chaining operations), while ensuring that you are still clearly explaining, both to your future self and others, what you are doing and why you are doing it.\n\n\n\n\n\n\nCautionQuick Tip\n\n\n\nRStudio has a keyboard shortcut for %&gt;%\n\nWindows: Ctrl + Shift + M\nMac: cmd + shift + M",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "r_tidyverse_clean_wrangle.html#selecting-or-removing-columns-using-select",
    "href": "r_tidyverse_clean_wrangle.html#selecting-or-removing-columns-using-select",
    "title": "Cleaning and Wrangling Data",
    "section": "5 Selecting or removing columns using select()",
    "text": "5 Selecting or removing columns using select()\nWe’re ready to go back to our salmon dataset. The first issue is the extra columns All and notesRegCode. Let’s select only the columns we want, and assign this to a variable called catch_data.\n\ncatch_data &lt;- catch_original %&gt;%\n    select(Region, Year, Chinook, Sockeye, Coho, Pink, Chum)\n\nhead(catch_data)\n\n# A tibble: 6 × 7\n  Region  Year Chinook Sockeye  Coho  Pink  Chum\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 SSE     1886 0             5     0     0     0\n2 SSE     1887 0           155     0     0     0\n3 SSE     1888 0           224    16     0     0\n4 SSE     1889 0           182    11    92     0\n5 SSE     1890 0           251    42     0     0\n6 SSE     1891 0           274    24     0     0\n\n\nMuch better!\nThe select() function also allows you to say which columns you don’t want, by passing unquoted column names preceded by minus (-) signs:\n\ncatch_data &lt;- catch_original %&gt;%\n    select(-All,-notesRegCode)",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "r_tidyverse_clean_wrangle.html#quality-check",
    "href": "r_tidyverse_clean_wrangle.html#quality-check",
    "title": "Cleaning and Wrangling Data",
    "section": "6 Quality check",
    "text": "6 Quality check\nNow that we have the data we are interested in using, we should do a little quality check to see that everything seems as expected. One nice way of doing this is the glimpse() function.\n\ndplyr::glimpse(catch_data)\n\nRows: 1,708\nColumns: 7\n$ Region  &lt;chr&gt; \"SSE\", \"SSE\", \"SSE\", \"SSE\", \"SSE\", \"SSE\", \"SSE\", \"SSE\", \"SSE\",…\n$ Year    &lt;dbl&gt; 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 18…\n$ Chinook &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"3\", \"4\", \"5\", \"9…\n$ Sockeye &lt;dbl&gt; 5, 155, 224, 182, 251, 274, 207, 189, 253, 408, 989, 791, 708,…\n$ Coho    &lt;dbl&gt; 0, 0, 16, 11, 42, 24, 11, 1, 5, 8, 192, 161, 132, 139, 84, 107…\n$ Pink    &lt;dbl&gt; 0, 0, 0, 92, 0, 0, 8, 187, 529, 606, 996, 2218, 673, 1545, 204…\n$ Chum    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 1, 2, 0, 0, 0, 102, 343…\n\n\n\n\n\n\n\n\nNoteExercise\n\n\n\nExamine the output of the glimpse() function call. Does anything seem amiss with this data set that might warrant fixing?\n\n\nAnswer:\n\nThe Chinook catch data are character class. Let’s fix it using the function mutate() before moving on.",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "r_tidyverse_clean_wrangle.html#changing-column-content-using-mutate",
    "href": "r_tidyverse_clean_wrangle.html#changing-column-content-using-mutate",
    "title": "Cleaning and Wrangling Data",
    "section": "7 Changing column content using mutate()",
    "text": "7 Changing column content using mutate()\nWe can use the mutate() function to change a column, or to create a new column. First, let’s try to convert the Chinook catch values to numeric type using the as.numeric() function, and overwrite the old Chinook column.\n\ncatch_clean &lt;- catch_data %&gt;%\n    mutate(Chinook = as.numeric(Chinook))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `Chinook = as.numeric(Chinook)`.\nCaused by warning:\n! NAs introduced by coercion\n\nhead(catch_clean)\n\n# A tibble: 6 × 7\n  Region  Year Chinook Sockeye  Coho  Pink  Chum\n  &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 SSE     1886       0       5     0     0     0\n2 SSE     1887       0     155     0     0     0\n3 SSE     1888       0     224    16     0     0\n4 SSE     1889       0     182    11    92     0\n5 SSE     1890       0     251    42     0     0\n6 SSE     1891       0     274    24     0     0\n\n\nWe get a warning \"NAs introduced by coercion\" which is R telling us that it couldn’t convert every value to an integer and, for those values it couldn’t convert, it put an NA in its place. This is behavior we commonly experience when cleaning data sets and it’s important to have the skills to deal with it when it comes up.\nTo investigate, let’s isolate the issue. We can find out which values are NAs with a combination of is.na() and which(), and save that to a variable called i.\n\ni &lt;- which(is.na(catch_clean$Chinook))\ni\n\n[1] 401\n\n\nIt looks like there is only one problem row, lets have a look at it in the original data.\n\ncatch_data[i,]\n\n# A tibble: 1 × 7\n  Region  Year Chinook Sockeye  Coho  Pink  Chum\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 GSE     1955 I            66     0     0     1\n\n\nWell that’s odd: The value in Chinook is the letter I. It turns out that this data set is from a PDF which was automatically converted into a csv and this value of I is actually a 1.\nLet’s fix it by incorporating the if_else() function to our mutate() call, which will change the value of the Chinook column to 1 if the value is equal to I, then will use as.numeric() to turn the character representations of numbers into numeric typed values.\n\ncatch_clean &lt;- catch_data %&gt;%\n    mutate(Chinook = if_else(condition = Chinook == \"I\", \n                             true = \"1\", \n                             false = Chinook),\n           Chinook = as.numeric(Chinook))\n\n##check\ncatch_clean[i, ]\n\n# A tibble: 1 × 7\n  Region  Year Chinook Sockeye  Coho  Pink  Chum\n  &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 GSE     1955       1      66     0     0     1",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "r_tidyverse_clean_wrangle.html#changing-shape-using-pivot_longer-and-pivot_wider",
    "href": "r_tidyverse_clean_wrangle.html#changing-shape-using-pivot_longer-and-pivot_wider",
    "title": "Cleaning and Wrangling Data",
    "section": "8 Changing shape using pivot_longer() and pivot_wider()",
    "text": "8 Changing shape using pivot_longer() and pivot_wider()\nThe next issue is that the data are in a wide format and we want the data in a long format instead. The function pivot_longer() from the tidyr package helps us do this conversion. If you do not remember all the arguments that go into pivot_longer() you can always call the help page by typing ?pivot_longer in the console.\n\ncatch_long &lt;- catch_clean %&gt;% \n    #pivot longer all columns except Region and Year\n    pivot_longer(\n        cols = -c(Region, Year),\n        names_to = \"species\",\n        values_to = \"catch\"\n    )\n\nhead(catch_long)\n\n# A tibble: 6 × 4\n  Region  Year species catch\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 SSE     1886 Chinook     0\n2 SSE     1886 Sockeye     5\n3 SSE     1886 Coho        0\n4 SSE     1886 Pink        0\n5 SSE     1886 Chum        0\n6 SSE     1887 Chinook     0\n\n\nThe syntax we used above for pivot_longer() might be a bit confusing so let’s walk though it.\n\nThe first argument to pivot_longer is the columns over which we are pivoting. You can select these by listing either the names of the columns you do want to pivot, or in this case, the names of the columns you are not pivoting over.\nThe names_to argument: this is the name of the column that you are creating from the column names of the columns you are pivoting over.\nThe values_to argument: the name of the column that you are creating from the values in the columns you are pivoting over.\n\nThe opposite of pivot_longer() is the pivot_wider() function. It works in a similar declarative fashion:\n\ncatch_wide &lt;- catch_long %&gt;%\n    pivot_wider(names_from = species,\n                values_from = catch)\n\nhead(catch_wide)\n\n# A tibble: 6 × 7\n  Region  Year Chinook Sockeye  Coho  Pink  Chum\n  &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 SSE     1886       0       5     0     0     0\n2 SSE     1887       0     155     0     0     0\n3 SSE     1888       0     224    16     0     0\n4 SSE     1889       0     182    11    92     0\n5 SSE     1890       0     251    42     0     0\n6 SSE     1891       0     274    24     0     0\n\n\nSame than we did above we can pull up the documentation of the function to remind ourselves what goes in which argument. Type ?pivot_wider in the console.",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "r_tidyverse_clean_wrangle.html#renaming-columns-with-rename",
    "href": "r_tidyverse_clean_wrangle.html#renaming-columns-with-rename",
    "title": "Cleaning and Wrangling Data",
    "section": "9 Renaming columns with rename()",
    "text": "9 Renaming columns with rename()\nIf you scan through the data, you may notice the values in the catch column are very small (these are supposed to be annual catches). If we look at the metadata we can see that the catch column is in thousands of fish, so let’s convert it before moving on.\nLet’s first rename the catch column to be called catch_thousands:\n\ncatch_long &lt;- catch_long %&gt;%\n    rename(catch_thousands = catch)\n\nhead(catch_long)\n\n# A tibble: 6 × 4\n  Region  Year species catch_thousands\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;\n1 SSE     1886 Chinook               0\n2 SSE     1886 Sockeye               5\n3 SSE     1886 Coho                  0\n4 SSE     1886 Pink                  0\n5 SSE     1886 Chum                  0\n6 SSE     1887 Chinook               0\n\n\n\n\n\n\n\n\nImportantnames() versus rename()\n\n\n\nMany people use the base R function names() to rename columns, often in combination with column indexing that relies on columns being in a particular order. Column indexing is often also used to select columns instead of the select() function from dplyr. Although these methods work just fine, they do have one major drawback: in most implementations they rely on you knowing exactly the column order your data is in.\nTo illustrate why your knowledge of column order isn’t reliable enough for these operations, considering the following scenario:\nYour colleague emails you letting you know that she has an updated version of the conductivity-temperature-depth data from this year’s research cruise, and sends it along. Excited, you re-run your scripts that use this data for your phytoplankton research. You run the script and suddenly all of your numbers seem off. You spend hours trying to figure out what is going on.\nUnbeknownst to you, your colleagues bought a new sensor this year that measures dissolved oxygen. Because of the new variables in the data set, the column order is different. Your script which previously renamed the fourth column, SAL_PSU to salinity now renames the fourth column, O2_MGpL to salinity. No wonder your results looked so weird, good thing you caught it!\nIf you had written your code so that it doesn’t rely on column order, but instead renames columns using the rename() function, the code would have run just fine (assuming the name of the original salinity column didn’t change, in which case the code would have thrown an error in an obvious way). This is an example of a defensive coding strategy, where you try to anticipate issues before they arise, and write your code in such a way as to keep the issues from happening.",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "r_tidyverse_clean_wrangle.html#adding-columns-using-mutate",
    "href": "r_tidyverse_clean_wrangle.html#adding-columns-using-mutate",
    "title": "Cleaning and Wrangling Data",
    "section": "10 Adding columns using mutate()",
    "text": "10 Adding columns using mutate()\nNow let’s use mutate() again to create a new column called catch with units of fish (instead of thousands of fish).\n\ncatch_long &lt;- catch_long %&gt;%\n    mutate(catch = catch_thousands * 1000)\n\nhead(catch_long)\n\nLet’s remove the catch_thousands column for now since we don’t need it. Note that here we have added to the expression we wrote above by adding another function call (mutate) to our expression. This takes advantage of the pipe operator by grouping together a similar set of statements, which all aim to clean up the catch_clean data frame.\n\ncatch_long &lt;- catch_long %&gt;%\n    mutate(catch = catch_thousands * 1000) %&gt;%\n    select(-catch_thousands)\n\nhead(catch_long)\n\n# A tibble: 6 × 4\n  Region  Year species catch\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 SSE     1886 Chinook     0\n2 SSE     1886 Sockeye  5000\n3 SSE     1886 Coho        0\n4 SSE     1886 Pink        0\n5 SSE     1886 Chum        0\n6 SSE     1887 Chinook     0\n\n\nWe’re now ready to start analyzing the data.",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "r_tidyverse_clean_wrangle.html#summary-statistics-using-group_by-and-summarize",
    "href": "r_tidyverse_clean_wrangle.html#summary-statistics-using-group_by-and-summarize",
    "title": "Cleaning and Wrangling Data",
    "section": "11 Summary statistics using group_by() and summarize()",
    "text": "11 Summary statistics using group_by() and summarize()\nSuppose we are now interested in getting the average catch per region. In our initial data exploration we saw there are 18 regions, we can easily see their names again:\n\nunique(catch_original$Region)\n\n [1] \"SSE\" \"NSE\" \"YAK\" \"GSE\" \"BER\" \"COP\" \"PWS\" \"CKI\" \"BRB\" \"KSK\" \"YUK\" \"NRS\"\n[13] \"KTZ\" \"KOD\" \"CHG\" \"SOP\" \"ALU\" \"NOP\"\n\n\nThink about how we would calculate the average catch per region “by hand”. It would be something like this:\n\nWe start with our table and notice there are multiple regions in the “Regions” column.\nWe split our original table to group all observations from the same region together.\nWe calculate the average catch for each of the groups we form.\nThen we combine the values for average catch per region into a single table.\n\n\n\n\n\n\n\n\nAnalyses like this conform to what is known as the Split-Apply-Combine strategy. This strategy follows the three steps we explained above:\n\nSplit: Split the data into logical groups (e.g., region, species, etc.)\nApply: Calculate some summary statistic on each group (e.g. mean catch by year, number of individuals per species)\nCombine: Combine the statistic calculated on each group back together into a single table\n\nThe dplyr library lets us easily employ the Split-Apply-Combine strategy by using the group_by() and summarize() functions:\n\nmean_region &lt;- catch_long %&gt;%\n    group_by(Region) %&gt;%\n    summarize(mean_catch = mean(catch))\n\nhead(mean_region)\n\n# A tibble: 6 × 2\n  Region mean_catch\n  &lt;chr&gt;       &lt;dbl&gt;\n1 ALU        40384.\n2 BER        16373.\n3 BRB      2709796.\n4 CHG       315487.\n5 CKI       683571.\n6 COP       179223.\n\n\nLet’s see how the previous code implements the Split-Apply-Combine strategy:\n\ngroup_by(Region): this is telling R to split the dataframe and create a group for each different value in the column Region. R just keeps track of the groups, it doesn’t return separate dataframes per region.\nmean(catch): here mean is the function we want to apply to the column catch in each group.\nsummarize(catch = mean(catch)) the function summarize() is used to combine the results of mean(catch) in each group into a single table. The argument mean_catch = mean(catch) indicates that the column having the results of mean(catch) will be named mean_catch.\n\nAnother common use of group_by() followed by summarize() is to count the number of rows in each group. We have to use a special function from dplyr, n().\n\nn_region &lt;- catch_long %&gt;%\n    group_by(Region) %&gt;%\n    summarize(n = n())\n\nhead(n_region)\n\n# A tibble: 6 × 2\n  Region     n\n  &lt;chr&gt;  &lt;int&gt;\n1 ALU      435\n2 BER      510\n3 BRB      570\n4 CHG      550\n5 CKI      525\n6 COP      470\n\n\n\n\n\n\n\n\nCautionTry using count()\n\n\n\nIf you are finding that you are reaching for this combination of group_by(), summarize() and n() a lot, there is a helpful dplyr function count() that accomplishes this in one function!\n\n\n\n\n\n\n\n\nNoteExercise\n\n\n\n\nFind another grouping and statistic to calculate for each group.\nFind out if you can group by multiple variables.\n\n\n\nAnswer\n## for example:\ncatch_year_sp &lt;- catch_long %&gt;%\n    group_by(Year, species) %&gt;%\n    summarize(total_year = sum(catch, na.rm = T))",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "r_tidyverse_clean_wrangle.html#filtering-rows-using-filter",
    "href": "r_tidyverse_clean_wrangle.html#filtering-rows-using-filter",
    "title": "Cleaning and Wrangling Data",
    "section": "12 Filtering rows using filter()",
    "text": "12 Filtering rows using filter()\nWe use the filter() function to filter our data.frame to rows matching some condition. It’s similar to subset() from base R.\nLet’s go back to our original data.frame and do some filter()ing:\n\nsse_catch &lt;- catch_long %&gt;%\n    filter(Region == \"SSE\")\n\nhead(sse_catch)\n\n# A tibble: 6 × 4\n  Region  Year species catch\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 SSE     1886 Chinook     0\n2 SSE     1886 Sockeye  5000\n3 SSE     1886 Coho        0\n4 SSE     1886 Pink        0\n5 SSE     1886 Chum        0\n6 SSE     1887 Chinook     0\n\n\n\n\n\n\n\n\nNoteExercise\n\n\n\n\nFilter to just catches of over one million fish\nFilter to just Chinook from the SSE region\n\n\n\nAnswer\n## Catches over a million fish\ncatch_million &lt;- catch_long %&gt;%\n    filter(catch &gt; 1000000)\n\n## Chinook from SSE data\nchinook_see &lt;- catch_long %&gt;%\n    filter(Region == \"SSE\",\n           species == \"Chinook\")\n\n## OR\nchinook_see &lt;- catch_long %&gt;%\n    filter(Region == \"SSE\" & species == \"Chinook\")",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "r_tidyverse_clean_wrangle.html#sorting-your-data-using-arrange",
    "href": "r_tidyverse_clean_wrangle.html#sorting-your-data-using-arrange",
    "title": "Cleaning and Wrangling Data",
    "section": "13 Sorting your data using arrange()",
    "text": "13 Sorting your data using arrange()\nThe arrange() function is used to sort the rows of a data.frame. Two common cases to use arrange() are:\n\nTo calculate a cumulative sum (with cumsum()) so row order matters\nTo display a table (like in an .qmd document) in sorted order\n\nLet’s re-calculate mean catch by region, and then arrange() the output by mean catch:\n\nmean_region &lt;- catch_long %&gt;%\n    group_by(Region) %&gt;%\n    summarize(mean_catch = mean(catch)) %&gt;%\n    arrange(mean_catch)\n\nhead(mean_region)\n\n# A tibble: 6 × 2\n  Region mean_catch\n  &lt;chr&gt;       &lt;dbl&gt;\n1 BER        16373.\n2 KTZ        18836.\n3 ALU        40384.\n4 NRS        51503.\n5 KSK        67642.\n6 YUK        68646.\n\n\nThe default sorting order of arrange() is to sort in ascending order. To reverse the sort order, wrap the column name inside the desc() function:\n\nmean_region &lt;- catch_long %&gt;%\n    group_by(Region) %&gt;%\n    summarize(mean_catch = mean(catch)) %&gt;%\n    arrange(desc(mean_catch))\n\nhead(mean_region)\n\n# A tibble: 6 × 2\n  Region mean_catch\n  &lt;chr&gt;       &lt;dbl&gt;\n1 SSE      3184661.\n2 BRB      2709796.\n3 NSE      1825021.\n4 KOD      1528350 \n5 PWS      1419237.\n6 SOP      1110942.",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "r_tidyverse_clean_wrangle.html#splitting-a-column-using-separate-and-unite",
    "href": "r_tidyverse_clean_wrangle.html#splitting-a-column-using-separate-and-unite",
    "title": "Cleaning and Wrangling Data",
    "section": "14 Splitting a column using separate() and unite()",
    "text": "14 Splitting a column using separate() and unite()\nThe separate() function allow us to easily split a single column into numerous. Its complement, the unite() function, allows us to combine multiple columns into a single one.\nThis can come in really handy when we need to split a column into two pieces by a consistent separator (like a dash).\nLet’s make a new data.frame with fake data to illustrate this. Here we have a set of site identification codes with information about the island where the site is (the first 3 letters) and a site number (the 3 numbers). If we want to group and summarize by island, we need a column with just the island information.\n\nsites_df &lt;- data.frame(site = c(\"HAW-101\",\n                                \"HAW-103\",\n                                \"OAH-320\",\n                                \"OAH-219\",\n                                \"MAU-039\"))\n\nsites_df %&gt;%\n    separate(site, c(\"island\", \"site_number\"), \"-\")\n\n  island site_number\n1    HAW         101\n2    HAW         103\n3    OAH         320\n4    OAH         219\n5    MAU         039\n\n\n\n\n\n\n\n\nNoteExercise\n\n\n\nSplit the city column in the data frame cities_df into city and state_code columns\n\n## create `cities_df`\ncities_df &lt;- data.frame(city = c(\"Juneau AK\",\n                                 \"Sitka AK\",\n                                 \"Anchorage AK\"))\n\n\n\nAnswer\ncolnames(cities_df)\n\ncities_clean &lt;- cities_df %&gt;%\n    separate(city, c(\"city\", \"state_code\"), \" \")\n\n\n\n\nThe unite() function does just the reverse of separate(). If we have a data.frame that contains columns for year, month, and day, we might want to unite these into a single date column.\n\ndates_df &lt;- data.frame(\n    year = c(\"1930\",\n             \"1930\",\n             \"1930\"),\n    month = c(\"12\",\n              \"12\",\n              \"12\"),\n    day = c(\"14\",\n            \"15\",\n            \"16\")\n)\n\ndates_df %&gt;%\n    unite(date, year, month, day, sep = \"-\")\n\n        date\n1 1930-12-14\n2 1930-12-15\n3 1930-12-16",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "r_tidyverse_clean_wrangle.html#now-all-together",
    "href": "r_tidyverse_clean_wrangle.html#now-all-together",
    "title": "Cleaning and Wrangling Data",
    "section": "15 Now, all together!",
    "text": "15 Now, all together!\nWe just ran through the various things we can do with dplyr and tidyr but if you’re wondering how this might look in a real analysis. Let’s look at that now:\n\ncatch_original &lt;- read_csv(\"https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1\")\n\nmean_region &lt;- catch_original %&gt;%\n  select(-All, -notesRegCode) %&gt;% \n  mutate(Chinook = if_else(Chinook == \"I\", \"1\", Chinook)) %&gt;% \n  mutate(Chinook = as.numeric(Chinook)) %&gt;% \n  pivot_longer(-c(Region, Year), \n               names_to = \"species\", \n               values_to = \"catch\") %&gt;%\n  mutate(catch = catch*1000) %&gt;% \n  group_by(Region) %&gt;% \n  summarize(mean_catch = mean(catch)) %&gt;% \n  arrange(desc(mean_catch))\n\nhead(mean_region)\n\n# A tibble: 6 × 2\n  Region mean_catch\n  &lt;chr&gt;       &lt;dbl&gt;\n1 SSE      3184661.\n2 BRB      2709796.\n3 NSE      1825021.\n4 KOD      1528350 \n5 PWS      1419237.\n6 SOP      1110942.\n\n\nWe have completed our lesson on Cleaning and Wrangling data. Before we break, let’s practice our Git workflow.\n\n\n\n\n\n\nTipSteps\n\n\n\n\nSave the .qmd you have been working on for this lesson.\nRender the Quarto file. This is a way to test everything in your code is working.\nStage (Add) &gt; Commit &gt; Pull &gt; Push",
    "crumbs": [
      "Cleaning and Wrangling Data"
    ]
  },
  {
    "objectID": "reproducibility.html",
    "href": "reproducibility.html",
    "title": "1 Intro to Reproducible Workflows",
    "section": "",
    "text": "TipLearning Objectives\n\n\n\n\nIntroduce the concept of reproducibility\nUnderstand the benefits of setting reproducible workflows\nDiscuss reproducibility best practices: file system structure, file organization, robust file paths!",
    "crumbs": [
      "1 Intro to Reproducible Workflows"
    ]
  },
  {
    "objectID": "reproducibility.html#slides",
    "href": "reproducibility.html#slides",
    "title": "1 Intro to Reproducible Workflows",
    "section": "1 Slides",
    "text": "1 Slides",
    "crumbs": [
      "1 Intro to Reproducible Workflows"
    ]
  },
  {
    "objectID": "reproducibility.html#more-on-reproducible-workflows",
    "href": "reproducibility.html#more-on-reproducible-workflows",
    "title": "1 Intro to Reproducible Workflows",
    "section": "2 More on Reproducible Workflows",
    "text": "2 More on Reproducible Workflows\n\nBest Practices for Writing Reproducible Code, University of Utrecht\nA Guide to Reproducible Code in Ecology and Evolution, British Ecological Society\nReproducibility Lesson, LTER Synthesis Skills for Early Career Researchers\nEDS 221 (2023), Lesson 1 and Lesson 2, UCSB MEDS, By Allison Horst\nGitHub Clinic, Openscapes\nBuilding reproducible analytical pipelines with R, Bruno Rodrigues",
    "crumbs": [
      "1 Intro to Reproducible Workflows"
    ]
  },
  {
    "objectID": "slides/r_programming_introduction/slides4_functions.html#title-slide",
    "href": "slides/r_programming_introduction/slides4_functions.html#title-slide",
    "title": "coreDUML",
    "section": "",
    "text": "Functions in R\nAn introduction to programming in R\n\n\nNCEAS Learning Hub"
  },
  {
    "objectID": "slides/r_programming_introduction/slides3_data_structures.html#title-slide",
    "href": "slides/r_programming_introduction/slides3_data_structures.html#title-slide",
    "title": "coreDUML",
    "section": "",
    "text": "Data types & structures in R\nAn introduction to programming in R\n\nNCEAS Learning Hub"
  },
  {
    "objectID": "github_introduction.html",
    "href": "github_introduction.html",
    "title": "Git and GitHub",
    "section": "",
    "text": "TipLearning Objectives\n\n\n\n\nApply the principles of Git to track and manage changes of a project\nUtilize the Git workflow including pulling changes, staging modified files, committing changes, pulling again to incorporate remote changes, and pushing changes to a remote repository\nCreate and configure Git repositories using different workflows"
  },
  {
    "objectID": "github_introduction.html#introduction-to-version-control",
    "href": "github_introduction.html#introduction-to-version-control",
    "title": "Git and GitHub",
    "section": "1 Introduction to Version Control",
    "text": "1 Introduction to Version Control\n\n\n\n\n\nEvery file changes throughout the scientific process. Manuscripts are edited. Figures get revised. Code gets fixed when bugs are discovered. Sometimes those fixes lead to even more bugs, leading to more changes in the code base. Data files get combined. Those same files are split and combined again. In just one research project, we can expect thousands of changes!\nThese changes are important to track, and yet, we often use simplistic file names to do so. Many of us have experienced renaming a document or script multiple times with the disingenuous addition of “final” to the file name.\nA better way: version control\nVersion control provides an organized and transparent way to track changes in code and files. This practice was designed for software development, but is easily applicable to scientific programming.\nBenefits to using a version control software include:\n\nMaintain a history of project development while keeping your workspace clean\nFacilitate collaboration and transparency when working on teams\nExplore bugs or new features without disrupting your team’s work\nand more!\n\nThe version control system we’ll be diving into is Git, the most widely used modern version control system in the world."
  },
  {
    "objectID": "github_introduction.html#introduction-to-git-github",
    "href": "github_introduction.html#introduction-to-git-github",
    "title": "Git and GitHub",
    "section": "2 Introduction to Git + GitHub",
    "text": "2 Introduction to Git + GitHub\nLet’s start with a motivating example that’s representative of the types of problems Git can help us solve.\nFull Screen\n\n\nWith Git we can enhance our workflow:\n\nEliminate the need for cryptic filenames and comments to track our work.\nProvide detailed descriptions of our changes through commits, making it easier to understand the reasons behind code modifications.\nWork on multiple branches simultaneously, allowing for parallel development, and optionally merge them together.\nUse commits to access and even execute older versions of our code.\nAssign meaningful tags to specific versions of our code.\nMultiple individuals can work on the same analysis concurrently on their own computers, with the ability to merge everyone’s changes together.\n\n\n\n2.1 What exactly are Git and GitHub?\n\nGit: an open-source version control software\n\ndesigned to manage the versioning and tracking of files and project history\noperates locally on your computer, allowing you to create repositories and track changes\nprovides features such as committing changes, branching and merging code, reverting to previous versions, and managing project history\nworks directly with the files on your computer and does not require a network connection for most operations\nprimarily used through the command-line interface (CLI, e.g. Terminal), but also has various GUI tools available (e.g. RStudio IDE)\n\n\n\n\n\n\nGitHub: an online platform and service built around Git\n\nprovides a centralized hosting platform for Git repositories\nallows us to store, manage, and collaborate on Git repositories in the cloud\noffers additional features on top of Git, including a web-based interface, issue tracking, project management tools, pull requests, code review, and collaboration features\nenables easy sharing of code with others, facilitating collaboration and contribution to open source projects\nprovides a social aspect, allowing users to follow projects, star repositories, and discover new code\n\n\n\n\n\n\n\n2.2 How local files, Git, and GitHub work together\nIt can be daunting to understand the moving parts of the Git / GitHub life cycle (i.e. how file changes are tracked locally within repositories, then stored for safe-keeping and collaboration on remote repositories, then brought back down to a local machine(s) for continued development). It gets easier with practice, but here’s a high-level overview of how things work:\n\n2.2.1 What is the difference between a “normal” folder vs. a Git repository?\nLet’s pretend that we create a folder, called myFolder/, and add two files: myData.csv and myAnalysis.R. The contents of this folder are not currently version-controlled – meaning, for example, that if we make changes to myAnalysis.R that don’t work out, we have no way of accessing or reverting back to a previous version of myAnalysis.R (without remembering or rewriting things, of course).\nGit allows you to turn any “normal” folder, like myFolder/, into a Git repository – this is often referenced as “initializing a Git repository”. When you initialize a folder on your local computer as a Git repository, a hidden .git/ folder is created within that folder (e.g. myFolder/.git/). This .git/ folder is the Git repository.\nAs you use Git commands to capture versions or “snapshots” of your work, those versions (and their associated metadata) get stored within the .git/ folder. This allows you to access and/or recover any previous versions of your work. If you delete .git/, you delete your project’s history.\nHere is our example folder / Git repository represented visually:\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.2 How do I tell Git to preserve versions of my local working files?\nGit was built as a command-line tool, meaning we can use Git commands in the command line (e.g. Terminal, Git Bash, etc.) to take “snapshots” of our local working files. Alternatively, RStudio provides buttons that easily execute these Git commands.\nGenerally, that workflow looks something like this:\n\nMake changes to a file(s) (e.g. myAnalysis.R) in your working directory.\nStage the file(s) using git add myAnalysis.R (or git add . to stage multiple changed files at once). This lets Git know that you’d like to include the file(s) in your next commit.\nCommit the file(s) using git commit -m \"a message describing my changes\". This records those changes (along with a descriptive message) as a “snapshot” or version in the local repository (i.e. the .git/ folder).\n\n\n\n2.2.3 How do I send work from my local computer to GitHub?\nThe last step is synchronizing the changes made to our local repository with a remote repository (this remote repository is often stored on GitHub). The git push command is used to send local commits up to a remote repository. The git pull command is used to fetch changes from a remote repository and merge them into the local repository – pulling will become a regular part of your workflow when collaborating with others, or even when working alone but on different machines (e.g. a laptop at home and a desktop at the office).\nA basic git workflow represented as two islands, one with “local repo” and “working directory”, and another with “remote repo.” Bunnies move file boxes from the working directory to the staging area, then with Commit move them to the local repo. Bunnies in rowboats move changes from the local repo to the remote repo (labeled “PUSH”) and from the remote repo to the working directory (labeled “PULL”).\n\n\n\n\nArtwork by Allison Horst\n\n\n\n\n\n2.3 Let’s Look at a GitHub Repository\nThis screen shows the copy of a repository stored on GitHub, with its list of files, when the files and directories were last modified, and some information on who made the most recent changes.\n\n\n\nIf we drill into the “commits” for the repository, we can see the history of changes made to all of the files. Looks like kellijohnson was working on the project and fixing errors in December:\n\n\n\nAnd finally, if we drill into one of the changes made on December 20, we can see exactly what was changed in each file:\n\n\n\nTracking these changes, how they relate to released versions of software and files is exactly what Git and GitHub are good for. And we will show how they can really be effective for tracking versions of scientific code, figures, and manuscripts to accomplish a reproducible workflow.\n\n\n2.4 Git Vocabulary & Commands\nWe know the world of Git and GitHub can be daunting. Use these tables as references while you use Git and GitHub, and we encourage you to build upon this list as you become more comfortable with these tools.\nThis table contains essential terms and commands that complement intro to Git skills. They will get you far on personal and individual projects.\n\nEssential Git Commands\n\n\n\n\n\n\n\nTerm\nGit Command(s)\nDefinition\n\n\n\n\nAdd/Stage\ngit add [file]\nStaging marks a modified file in its current version to go into your next commit snapshot. You can also stage all modified files at the same time using git add .\n\n\nCommit\ngit commit\nRecords changes to the repository.\n\n\nCommit Message\ngit commit -m \"my commit message\"\nRecords changes to the repository and include a descriptive message (you should always include a commit message!).\n\n\nFetch\ngit fetch\nRetrieves changes from a remote repository but does not merge them into your local working file(s).\n\n\nPull\ngit pull\nRetrieves changes from a remote repository and merges them into your local working file(s).\n\n\nPush\ngit push\nSends local commits to a remote repository.\n\n\nStatus\ngit status\nShows the current status of the repository, including (un)staged files and branch information.\n\n\n\nThis table includes more advanced Git terms and commands that are commonly used in both individual and collaborative projects.\n\nAdvanced Git Commands\n\n\n\n\n\n\n\nTerm\nGit Command(s)\nDefinition\n\n\n\n\nBranch\ngit branch\nLists existing branches or creates a new branch.\n\n\nCheckout\ngit checkout [branch]\nSwitches to a different branch or restores files from a specific commit.\n\n\nClone\ngit clone [repository]\nCreates a local copy of a remote repository.\n\n\nDiff\ngit diff\nShows differences between files, commits, or branches.\n\n\nFork\n-\nCreates a personal copy of a repository under your GitHub account for independent development.\n\n\nLog\ngit log\nDisplays the commit history of the repository.\n\n\nMerge\ngit merge [branch]\nIntegrates changes from one branch into another branch.\n\n\nMerge Conflict\n-\nOccurs when Git cannot automatically merge changes from different branches, requiring manual resolution.\n\n\nPull Request (PR)\n-\nA request to merge changes from a branch into another branch, typically in a collaborative project.\n\n\nRebase\ngit rebase\nIntegrates changes from one branch onto another by modifying commit history.\n\n\nRemote\ngit remote\nManages remote repositories linked to the local repository.\n\n\nRepository\ngit init\nA directory where Git tracks and manages files and their versions.\n\n\nStash\ngit stash\nTemporarily saves changes that are not ready to be committed.\n\n\nTag\ngit tag\nAssigns a label or tag to a specific commit.\n\n\n\nGit has a rich set of commands and features, and there are many more terms beyond either table. Learn more by visiting the git documentation."
  },
  {
    "objectID": "github_introduction.html#exercise-1-create-a-remote-repository-on-github",
    "href": "github_introduction.html#exercise-1-create-a-remote-repository-on-github",
    "title": "Git and GitHub",
    "section": "3 Exercise 1: Create a remote repository on GitHub",
    "text": "3 Exercise 1: Create a remote repository on GitHub\n\n\n\n\n\n\nTipSetup\n\n\n\n\nLogin to GitHub\nClick the New repository button\nName it {FIRSTNAME}_test\nAdd a short description\nCheck the box to add a README.md file\nAdd a .gitignore file using the R template\nSet the LICENSE to Apache 2.0\n\n\n\nIf you were successful, it should look something like this:\n\n\n\n\n\nYou’ve now created your first repository! It has a couple of files that GitHub created for you: README.md, LICENSE, and .gitignore.\n\n\n\n\n\n\nNoteREADME.md files are used to share important information about your repository\n\n\n\nYou should always add a README.md to the root directory of your repository – it is a markdown file that is rendered as HTML and displayed on the landing page of your repository. This is a common place to include any pertinent information about what your repository contains, how to use it, etc.\n\n\n\n\n \n\nFor simple changes to text files, such as the README.md, you can make edits directly in the GitHub web interface.\n\n\n\n\n\n\nNoteChallenge\n\n\n\nNavigate to the README.md file in the file listing, and edit it by clicking on the pencil icon (top right of file). This is a regular Markdown file, so you can add markdown text. Add a new level-2 header called “Purpose” and add some bullet points describing the purpose of the repo. When done, add a commit message, and hit the Commit changes button.\n\n\n\n\n\n\n\nCongratulations, you’ve now authored your first versioned commit! If you navigate back to the GitHub page for the repository, you’ll see your commit listed there, as well as the rendered README.md file.\n\n\n\n\n\nThe GitHub repository landing page provides us with lots of useful information. To start, we see:\n\nall of the files in the remote repository\nwhen each file was last edited\nthe commit message that was included with each file’s most recent commit (which is why it’s important to write good, descriptive commit messages!)\n\nAdditionally, the header above the file listing shows the most recent commit, along with its commit message, and a unique ID (assigned by Git) called a SHA. The SHA (aka hash) identifies the specific changes made, when they were made, and by who. If you click on the SHA, it will display the set of changes made in that particular commit.\n\n\n\n\n\n\nCautionWhat should I write in my commit message?\n\n\n\nWriting effective Git commit messages is essential for creating a meaningful and helpful version history in your repository. It is crucial to avoid skipping commit messages or resorting to generic phrases like “Updates.” When it comes to following best practices, there are several guidelines to enhance the readability and maintainability of the codebase.\nHere are some guidelines for writing effective Git commit messages:\n\nBe descriptive and concise: Provide a clear and concise summary of the changes made in the commit. Aim to convey the purpose and impact of the commit in a few words.\nUse imperative tense: Write commit messages in the imperative tense, as if giving a command. For example, use “Add feature” instead of “Added feature” or “Adding feature.” This convention aligns with other Git commands and makes the messages more actionable.\nSeparate subject and body: Start with a subject line, followed by a blank line, and then provide a more detailed explanation in the body if necessary. The subject line should be a short, one-line summary, while the body can provide additional context, motivation, or details about the changes.\nLimit the subject line length: Keep the subject line within 50 characters or less. This ensures that the commit messages are easily scannable and fit well in tools like Git logs.\nCapitalize and punctuate properly: Begin the subject line with a capital letter and use proper punctuation. This adds clarity and consistency to the commit messages.\nFocus on the “what” and “why”: Explain what changes were made and why they were made. Understanding the motivation behind a commit helps future researchers and collaborators (including you!) comprehend its purpose.\nUse present tense for subject, past tense for body: Write the subject line in present tense as it represents the current state of the codebase. Use past tense in the body to describe what has been done.\nReference relevant issues: If the commit is related to a specific issue or task, include a reference to it. For example, you can mention the issue number or use keywords like “Fixes,” “Closes,” or “Resolves” followed by the issue number."
  },
  {
    "objectID": "github_introduction.html#exercise-2-clone-your-repository-and-use-git-locally-in-rstudio",
    "href": "github_introduction.html#exercise-2-clone-your-repository-and-use-git-locally-in-rstudio",
    "title": "Git and GitHub",
    "section": "4 Exercise 2: clone your repository and use Git locally in RStudio",
    "text": "4 Exercise 2: clone your repository and use Git locally in RStudio\nCurrently, our repository just exists on GitHub as a remote repository. It’s easy enough to make changes to things like our README.md file (as demonstrated above), from the web browser, but that becomes a lot harder (and discouraged) for scripts and other code files. In this exercise, we’ll bring a copy of this remote repository down to our local computer (aka clone this repository) so that we can work comfortably in RStudio.\n\n\n\n\n\n\nImportantAn important distinction\n\n\n\nWe refer to the remote copy of the repository that is on GitHub as the origin repository (the one that we cloned from), and the copy on our local computer as the local repository.\n\n\nStart by clicking the green Code button (top right of your file listing) and copying the URL to your clipboard (this URL represents the repository location):\n\n\n\n\n\n\n\nRStudio makes working with Git and version controlled files easy – to do so, you’ll need to be working within an R project folder. The following steps will look similar to those you followed when first creating an R Project, with a slight difference. Follow the instructions in the Setup box below to clone your remote repository to your local computer in RStudio:\n\n\n\n\n\n\nTipSetup\n\n\n\n\nClick File &gt; New Project\nSelect Version Control and paste the remote repository URL (which should be copied to your clipboard) in the Repository URL field\nPress Tab, which will auto-fill the Project directory name field with the same name as that of your remote repo – while you can name the local copy of the repository anything, it’s typical (and highly recommended) to use the same name as the GitHub repository to maintain the correspondence\n\n\n\n\n\n\n\n\n\nOnce you click Create Project, a new RStudio window will open with all of the files from the remote repository copied locally. Depending on how your version of RStudio is configured, the location and size of the panes may differ, but they should all be present – you should see a Git tab, as well as the Files tab, where you can view all of the files copied from the remote repo to this local repo.\n\n\n\n\nYou’ll note that there is one new file sam_test.Rproj, and three files that we created earlier on GitHub (.gitignore, LICENSE, and README.md).\nIn the Git tab, you’ll note that the one new file, sam_test.Rproj, is listed. This Git tab is the status pane that shows the current modification status of all of the files in the repository. Here, we see sam_test.Rproj is preceded by a ?? symbol to indicate that the file is currently untracked by Git. This means that we have not yet committed this file using Git (i.e. Git knows nothing about the file; hang tight, we’ll commit this file soon so that it’s tracked by Git). As you make version control decisions in RStudio, these icons will change to reflect the current version status of each of the files.\nInspect the history. Click on the History button in the Git tab to show the log of changes that have occurred – these changes will be identical to what we viewed on GitHub. By clicking on each row of the history, you can see exactly what was added and changed in each of the two commits in this repository.\n\n\n\n\n\n\n\n\nNoteChallenge\n\n\n\n\nMake a change to the README.md file – this time from RStudio – then commit the README.md change\nAdd a new section to your README.md called “Creator” using a level-2 header. Under it include some information about yourself. Bonus: Add some contact information and link your email using Markdown syntax.\n\n\n\nOnce you save, you’ll immediately see the README.md file show up in the Git tab, marked as a modification. Select the file in the Git tab, and click Diff to see the changes that you saved (but which are not yet committed to your local repository). Newly made changes are highlighted in green.\n\n\n\n\nCommit the changes. To commit the changes you made to the README.md file using RStudio’s GUI (Graphical User Interface), rather than the command line:\n\nStage (aka add) README.md by clicking the check box next to the file name – this tells Git which changes you want included in the commit and is analogous to using the git command, git add README.md, in the command line\nCommit README.md by clicking the Commit button and providing a descriptive commit message in the dialog box. Press the Commit button once you’re satisfied with your message. This is analogous to using the git command, git commit -m \"my commit message\", in the command line.\n\n\nA few notes about our local repository’s state:\n\nWe still have a file, sam_test.Rproj, that is listed as untracked (denoted by ?? in the Git tab).\nYou should see a message at the top of the Git tab that says, Your branch is ahead of ‘origin/main’ by 1 commit., which tells us that we have 1 commit in the local repository, but that commit has not yet been pushed up to the origin repository (aka remote repository on GitHub).\n\nCommit the remaining project file by staging/adding and committing it with an informative commit message.\n\nWhen finished, you’ll see that no changes remain in the Git tab, and the repository is clean.\nInspect the history. Note that under Changes, the message now says:\nYour branch is ahead of ‘origin/main’ by 2 commits.\nThese are the two commits that we just made, but have not yet been pushed to GitHub.\nClick on the History button to see a total of four commits in the local repository (the two we made directly to GitHub via the web browser and the two we made in RStudio).\nPush these changes to GitHub. Now that we’ve made and committed changes locally, we can push those changes to GitHub using the Push button. This sends your changes to the remote repository (on GitHub) leaving your repository in a totally clean and synchronized state (meaning your local repository and remote repository should look the same).\n\n\n\n\n\n\nNoteIf you are prompted to provide your GitHub username and password when Pushing…\n\n\n\nit’s a good indicator that you did not set your GitHub Personal Access Token (PAT) correctly. You can redo the steps outlined in the GitHub Authentication section to (re)set your PAT, then Push again.\n\n\n\n &lt;––&gt;\n\nIf you look at the History pane again, you’ll notice that the labels next to the most recent commit indicate that both the local repository (HEAD) and the remote repository (origin/HEAD) are pointing at the same version in the history. If we look at the commit history on GitHub, all the commits will be shown there as well.\n\n\n\n4.1 Defining Merge Method\n\n\n\n\n\n\nCautionSome Git configuration to surpress warning messages\n\n\n\nGit version 2.27 includes a new feature that allows users to specify the default method for integrating changes from a remote repository into a local repository, without receiving a warning (this warning is informative, but can get annoying). To suppress this warning for this repository only we need to configure Git by running this line of code in the Terminal:\n\ngit config pull.rebase false\n\npull.rebase false is a default strategy for pulling where Git will first try to auto-merge the files. If auto-merging is not possible, it will indicate a merge conflict (more on resolving merge conflicts in Collaborating with Git and GitHub).\nNote: Unlike when we first configured Git, we do not include the --global flag here (e.g. git config --global pull.rebase false). This sets this default strategy for this repository only (rather than globally for all your repositories). We do this because your chosen/default method of grabbing changes from a remote repository (e.g. pulling vs. rebasing) may change depending on collaborator/workflow preference."
  },
  {
    "objectID": "github_introduction.html#exercise-3-setting-up-git-on-an-existing-project",
    "href": "github_introduction.html#exercise-3-setting-up-git-on-an-existing-project",
    "title": "Git and GitHub",
    "section": "5 Exercise 3: Setting up Git on an existing project",
    "text": "5 Exercise 3: Setting up Git on an existing project\nThere are a number of different workflows for creating version-controlled repositories that are stored on GitHub. We started with Exercise 1 and Exercise 2 using one common approach: creating a remote repository on GitHub first, then cloning that repository to your local computer (you used your {FIRSTNAME}_test repo).\nHowever, you may find yourself in the situation where you have an existing directory (i.e. a “normal” folder) of code that you want to make a Git repository out of, and then send it to GitHub. In this last exercise, we will practice this workflow using your training_{USERNAME} project.\nFirst, switch to your training_{USERNAME} project using the RStudio project dropdown menu. The project drop down menu is in the upper right corner of your RStudio pane. Click the drop down next to your project name ({FIRSTNAME}_test), and then select the training_{USERNAME} project from the RECENT PROJECTS list.\nThere are a few approaches for turning an existing project folder into a Git repository, then sending it to GitHub – if you’re an R-user, the simplest way is to use the {usethis} package, which is built to automate tasks involved with project setup and development. However, you can also initialize a local git repository and set the remote repository from the command line (a language-agnostic workflow). Steps for both approaches are included below (demonstrated using your training_{USERNAME} project):\n\nUsing R & {usethis}Using the command line\n\n\n\nInstall the {usethis} package (if you haven’t done so already) by running the following in your Console:\n\n\ninstall.packages(\"usethis\")\n\n\nInitialize training_{USERNAME} as a Git repository by running usethis::use_git() in the Console. Choose yes when asked if it’s okay to commit any uncommitted files. Choose yes again if asked to restart R. Once complete, you should see the Git tab appear in your top left pane in RStudio and a .gitignore file appear in your Files tab.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote.gitignore files allow you to specify which files/folders you don’t want Git to track\n\n\n\nA .gitignore file is automatically created in the root directory of your project when you initialize it as a Git repository. You’ll notice that there are already some R / R Project-specific files that have been added by default.\nWhy is this useful? For many reasons, but possibly the greatest use-case is adding large files (GitHub has a file size limit of 2 GB) or files with sensitive information (e.g. keys, tokens) that you don’t want to accidentally push to GitHub.\nHow do I do this? Let’s say I create a file with sensitive information that I don’t want to push to GitHub. I can add a line to my .gitignore file:\n\n# added by default when I initalized my RProj as a Git Repository\n.Rproj.user\n.Rhistory\n.Rdata\n.httr-oauth\n.DS_Store\n.quarto\n\n# add file so that it doesn't get pushed to the remote repo (on GitHub); \ncontains_sensitive_info.R\n\nIf this file is currently untracked by Git, it should appear in my Git tab. Once I add it to the .gitignore and save the modified .gitignore file, you should see contains_sensitive_info.R disappear from the Git tab, and a modified .gitignore (denoted by a blue M) appear. Stage/commit/push this modified .gitignore file.\n\n\n\nCreate an upstream remote repository on GitHub by running usethis::use_github() in the Console. Your web browser should open up to your new GitHub repository, with the same name as your local Git repo/R Project.\n\n\n\n\n\n\n\n\n\n\n\nEnsure that your default branch is named main rather than master by:\n\nrunning git branch in the Terminal to list all your branches (you should currently only have one, which is your default)\nif it’s named master, run the following line in the Console to update it\n\n\n\nusethis::git_default_branch_rename(from = \"master\", to = \"main\")\n\nYou can verify that your update worked by running git branch once more in the Terminal.\n\n\n\n\n\n\nNoteWhy are we doing this?\n\n\n\nThe racist “master” terminology for git branches motivates us to update our default branch to “main” instead.\nThere is a push across platforms and software to update this historical default branch name from master to main. GitHub has already done so – you may have noticed that creating a remote repository first (like we did in Exercises 1 & 2) results in a default branch named main. Depending on your version of Git, however, you may need to set update the name manually when creating a local git repository first (as we’re doing here).\n\n\n\nYou’re now ready to edit, stage/add, commit, and push files to GitHub as practiced earlier!\n\n\n\n\n\n\n\nCautionChallenge: add a README.md file to training_{USERNAME}\n\n\n\nGitHub provides a button on your repo’s landing page for quickly adding a README.md file. Click the Add a README button and use markdown syntax to create a README.md. Commit the changes to your repository.\nGo to your local repository (in RStudio) and pull the changes you made.\n\n\n\n\nWhile we’ll be using the RStudio Terminal here, you can use any command-line interface (e.g. Mac Terminal, Git Bash, etc.) that allows for git interactions (if you plan to use a command-line interface that is not the RStudio Terminal, make sure to navigate to your project directory (e.g. using cd file/path/to/project/directory) before initializing your repository.\n\nInitialize training_{USERNAME} as a Git repository by running git init in the Terminal. You should get a message that says something like:\n\n\nInitialized empty Git repository in /home/username/training_username/.git/\n\n\n\n\n\n\n\nImportantYou may have to quit and reopen your RStudio session on the server for the Git tab to appear\n\n\n\nYou’ll likely need to help included-crab along in recognizing that this R Project has been initialized as a git repository – click Session &gt; Quit Session… &gt; New Session &gt; choose training_{USERNAME} to reopen your project.\n\n\nOnce complete, you should see the Git tab appear in your top left pane in RStudio and a .gitignore file appear in your Files tab.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote.gitignore files allow you to specify which files/folders you don’t want Git to track\n\n\n\nA .gitignore file is automatically created in the root directory of your project when you initialize it as a Git repository. You’ll notice that there are already some R / R Project-specific files that have been added by default.\nWhy is this useful? For many reasons, but possibly the greatest use-case is adding large files (GitHub has a file size limit of 2 GB) or files with sensitive information (e.g. keys, tokens) that you don’t want to accidentally push to GitHub.\nHow do I do this? Let’s say I create a file with sensitive information that I don’t want to push to GitHub. I can add a line to my .gitignore file:\n\n# added by default when I initalized my RProj as a Git Repository\n.Rproj.user\n.Rhistory\n.Rdata\n.httr-oauth\n.DS_Store\n.quarto\n\n# add file so that it doesn't get pushed to the remote repo (on GitHub); \ncontains_sensitive_info.R\n\nIf this file is currently untracked by Git, it should appear in my Git tab. Once I add it to the .gitignore and save the modified .gitignore file, you should see contains_sensitive_info.R disappear from the Git tab, and a modified .gitignore (denoted by a blue M) appear. Stage/commit/push this modified .gitignore file.\n\n\n\nEnsure that your default branch is named main rather than master by:\n\nrunning git branch in the Terminal to list all your branches (you should currently only have one, which is your default)\nif it’s named master, run the following line in the Terminal to update it\n\n\n\n# for Git version 2.28+ (check by running `git --version`)\n# this sets the default branch name to `main` for any new repos moving forward\ngit config --global init.defaultBranch main\n\n# for older versions of Git\n# this sets the default branch name to `main` ONLY for this repo \ngit branch -m master main\n\nYou can verify that your update worked by running git branch once more in the Terminal.\n\n\n\n\n\n\nNoteWhy are we doing this?\n\n\n\nThe racist “master” terminology for git branches motivates us to update our default branch to “main” instead.\nThere is a push across platforms and software to update this historical default branch name from master to main. GitHub has already done so – you may have noticed that creating a remote repository first (like we did in Exercises 1 & 2) results in a default branch named main. Depending on your version of Git, however, you may need to set update the name manually when creating a local git repository first (as we’re doing here).\n\n\n\nStage/Add your files. It’s helpful to first run git status to check the state of your local repository (particularly if you aren’t using RStudio / have access to a GUI with a Git tab-esque feature) – this will tell you which files have been modified or are untracked and that are currently unstaged (in red). What appears here should look just like what appears in the Git tab:\n\n\n\n\n\n\n\n\n\n\nRun git add . in the Terminal to stage all files at once (or git add {FILENAME} to stage individual files). Running git status again will show you which files have been staged (in green). You may have to refresh your Git tab to see the change in state reflected in the GUI.\n\n\n\n\n\n\n\n\n\n\nCommit your files by running git commit -m \"an informative commit message\" in the Terminal. Refreshing your Git tab will cause them to disappear (just as they do when you commit using RStudio’s GUI buttons). You can run git log in the Terminal to see a history of your past commits (currently, we only have this one).\n\n\n\n\n\n\n\n\n\n\n\nCreate an empty remote repository by logging into GitHub and creating a new repository, following the same steps as in Exercise 1. IMPORTANTLY, DO NOT initialize your remote repo with a README license, or .gitignore file – doing so now can lead to merge conflicts. We can add them after our local and remote repos are linked. Name your remote repository the same as your local repository (i.e. training_{USERNAME}).\nLink your remote (GitHub) repository to your local Git repository. Your empty GitHub repo conveniently includes instructions for doing so. Copy the code under push an existing repository from the command line to your clipboard, paste into your RStudio Terminal, and press return/enter.\n\n\n\n\n\n\n\n\n\n\nThese commands do three things:\n\nAdds the GitHub repository as the remote repository (i.e. links your local repo to the remote repo)\nRenames the default branch to main\nPushes the main branch to the remote GitHub repository\n\nHead back to your browser and refresh your GitHub repository page to see your files appear!\n\nYou’re now ready to edit, stage/add, commit, and push files to GitHub as practiced earlier!\n\n\n\n\n\n\n\nCautionChallenge: add a README.md file to training_{USERNAME}\n\n\n\nGitHub provides a button on your repo’s landing page for quickly adding a README.md file. Click the Add a README button and use markdown syntax to create a README.md. Commit the changes to your repository.\nGo to your local repository (in RStudio) and pull the changes you made."
  },
  {
    "objectID": "github_introduction.html#go-further-with-git",
    "href": "github_introduction.html#go-further-with-git",
    "title": "Git and GitHub",
    "section": "6 Go further with Git",
    "text": "6 Go further with Git\nThere’s a lot we haven’t covered in this brief tutorial. There are some great and much longer tutorials that cover advanced topics, such as:\n\nUsing Git on the command line\nResolving conflicts\nBranching and merging\nPull requests versus direct contributions for collaboration\nUsing .gitignore to protect sensitive data\nGitHub Issues - how to use them for project management and collaboration\n\nand much, much more."
  },
  {
    "objectID": "github_introduction.html#git-resources",
    "href": "github_introduction.html#git-resources",
    "title": "Git and GitHub",
    "section": "7 Git resources",
    "text": "7 Git resources\n\nPro Git Book\nHappy Git and GitHub for the useR\nGitHub Documentation\nLearn Git Branching is an interactive tool to learn Git on the command line\nSoftware Carpentry Version Control with Git\nBitbucket’s tutorials on Git Workflows"
  },
  {
    "objectID": "zotero.html",
    "href": "zotero.html",
    "title": "Zotero 201",
    "section": "",
    "text": "TipLearning Objectives\n\n\n\n\nCompare Zotero pros & cons to other reference managers\nConfigure general Zotero settings\nExpand Zotero usage through add-ons",
    "crumbs": [
      "Zotero 201"
    ]
  },
  {
    "objectID": "zotero.html#slides",
    "href": "zotero.html#slides",
    "title": "Zotero 201",
    "section": "1 Slides",
    "text": "1 Slides",
    "crumbs": [
      "Zotero 201"
    ]
  },
  {
    "objectID": "lecture_tidy_data.html",
    "href": "lecture_tidy_data.html",
    "title": "Tidy Data",
    "section": "",
    "text": "TipLearning Objectives\n\n\n\nLearn how to design and create effective data tables by:\n\napplying tidy and normalized data principles,\nfollowing best practices to format data tables’ content,\nrelating tables following relational data models principles, and\nunderstanding how to perform table joins.",
    "crumbs": [
      "Tidy Data"
    ]
  },
  {
    "objectID": "lecture_tidy_data.html#what-is-tidy-data",
    "href": "lecture_tidy_data.html#what-is-tidy-data",
    "title": "Tidy Data",
    "section": "1 What is tidy data?",
    "text": "1 What is tidy data?\nTidy data is a standardized way of organizing data tables that allows us to manage and analyze data efficiently, because it makes it straightforward to understand the corresponding variable and observation of each value. The  tidy data principles  are:\n\nEvery column is a variable.\nEvery row is an observation.\nEvery cell is a single value.\n\n\n\n\n\n\n\nTipTidy Data: A way of life\n\n\n\n\nTidy data is not a language or tool specific.\nTidy data is not an R thing.\nTidy data is not a tidyverse thing.\n\nTidy Data is a way to organize data that will make life easier for people working with data.\n(Allison Horst & Julia Lowndes)",
    "crumbs": [
      "Tidy Data"
    ]
  },
  {
    "objectID": "lecture_tidy_data.html#values-variables-observations-and-entities",
    "href": "lecture_tidy_data.html#values-variables-observations-and-entities",
    "title": "Tidy Data",
    "section": "2 Values, variables, observations, and entities",
    "text": "2 Values, variables, observations, and entities\nFirst, let’s get acquainted with our building blocks.\n\n\n\n\n\n\n\n\n\nConcept\nDefinition\n\n\n\n\n\n\nVariables\nA characteristic the is being measured, counted or described with data.\nExample: car type, salinity, year, height, mass.\n\n\n\n\nObservations\nA single “data point” for which the measure, count or description of one or more variables is recorded.\nExample: If you are collecting variables height, species, and location of plants, then each plant is an observation.\n\n\n\n\nValue\nThe record measured, count or description of a variable.\nExample: 3 ft\n\n\n\n\nEntity\nEach type of observation is an entity.\nExample: If you are collecting variables height, species, and location and site name of plants and where they are observed, then plants is an entity and site is an entity.",
    "crumbs": [
      "Tidy Data"
    ]
  },
  {
    "objectID": "lecture_tidy_data.html#assessing-tidy-data-principles",
    "href": "lecture_tidy_data.html#assessing-tidy-data-principles",
    "title": "Tidy Data",
    "section": "3 Assessing Tidy Data Principles",
    "text": "3 Assessing Tidy Data Principles\nThe following is an example of tidy data - it’s easy to see the three tidy data principles apply.",
    "crumbs": [
      "Tidy Data"
    ]
  },
  {
    "objectID": "lecture_tidy_data.html#recognizing-untidy-data",
    "href": "lecture_tidy_data.html#recognizing-untidy-data",
    "title": "Tidy Data",
    "section": "4 Recognizing untidy data",
    "text": "4 Recognizing untidy data\nAnything that does not follow the three tidy data principles is untidy data.\nThere are many ways in which data can become untidy, some can be noticed right away, while others are more subtle. In this section we will look at some examples of common untidy data situations.\n\n4.1 Example 1\nThe following is a screenshot of an actual dataset that came across NCEAS. We have all seen spreadsheets that look like this - and it is fairly obvious that whatever this is, it isn’t very tidy. Let’s dive deeper into why we consider it untidy data.\n\n\n4.1.1 Multiple tables\nTo begin with, notice there are actually three smaller tables within this table. Although for our human brain it is easy to see and interpret this, it is extremely difficult to get a computer to see it this way.\n\nHaving multiple tables within the same table will create headaches down the road should you try to read in this information using R or another programming language. Having multiple tables immediately breaks the tidy data principles, as we will see next.\n\n\n4.1.2 Inconsistent columns\nIn tidy data, each column corresponds to a single variable. If you look down a column, and see that multiple variables exist in the table, the data is not tidy. A good test for this can be to see if you think the column consists of only one unit type.\n\n\n\n4.1.3 Inconsistent rows\nThe second principle of tidy data is: every column must be a single observation. If you look across a single row, and you notice that there are clearly multiple observations in one row, the data are likely not tidy.\n\n\n\n4.1.4 Marginal sums and statistics\nMarginal sums and statistics are not considered tidy. They break principle one, “Every column is a variable”, because a marginal statistic does not represent the same variable as the values it is summarizing. They also break principle two, “Every row is an observation”, because they represent a combination of observations, rather than a single one.\n\n\n\n\n4.2 Example 2\nConsider the following table. It’s a single one this time! It shows data about species observed at a specific site and date. The column headers refer to the following:\n\ndate: date when a species was observed\nsite: site where a species was observed\nname: site’s name\naltitude: site’s altitude\nsp1code, sp2code: species code for two plants observed\nsp1height, sp2height: height of the plants observed\n\nTake a moment to see why this is not tidy data.\n\n\n4.2.1 Multiple Observations\nRemember that an observation is all the values measured for an individual entity.\nIf our entity is a single observed plant, then the values we measured are date and site of observation, the altitude, and the species code and height. This table breaks the second tidy data principles: Every row is an observation.\n\nPeople often refer to this as “wide format”, because the observations are spread across a wide number of columns. Note that, should one encounter a new species in the survey, we would have to add new columns to the table. This is difficult to analyze, understand, and maintain. To solve this problem, we can create a single column for species code and a single column for species height as in the following table.",
    "crumbs": [
      "Tidy Data"
    ]
  },
  {
    "objectID": "lecture_tidy_data.html#why-tidy-data",
    "href": "lecture_tidy_data.html#why-tidy-data",
    "title": "Tidy Data",
    "section": "5 Why Tidy Data?",
    "text": "5 Why Tidy Data?\n\nEfficiency: less re-creating the wheel. Easier to apply the same tools to different datasets.\nCollaboration: Makes it easier to work with others as you can work with the same tools in the same ways.\nReuse: It makes it easier to apply similar techniques and analysis across different or new datasets.\nGeneralizability: Tools built for one tidy data set can be used to multiple other datasets. Opening posibilities of data you can work with.\n\n\n“There is a specific advantage to placing varables in columns becasuse it allows R’s vectorized nature to shine. …most buit-in R functions work with vactors of values. That makes transforming tidy data feel particularly natural. (R for Data Science by Grolemund and Wickham)",
    "crumbs": [
      "Tidy Data"
    ]
  },
  {
    "objectID": "lecture_tidy_data.html#data-normalization",
    "href": "lecture_tidy_data.html#data-normalization",
    "title": "Tidy Data",
    "section": "6 Data Normalization",
    "text": "6 Data Normalization\n\n6.1 What is data normalization?\nData normalization is the process of creating normalized data, which are datasets free from data redundancy to simplify query, analysis, storing, and maintenance. In normalized data we organize data so that :\n\nEach table follows the tidy data principles\nWe have separate tables for each type of entity measured\nObservations (rows) are all unique\nEach column represents either an identifying variable or a measured variable\n\nIn denormalized data observations about different entities are combined. A good indication that a data table is denormalized and needs normalization is seeing the same column values repeated across multiple rows.\n\n\n6.2 Example\nIn the previous data table the row values for the last three columns are repeated.\n\nThis means the data is denormalized and it happens because each row has values about more than one entity:\n\n1st entity: individual plants found at that site, and\n2nd entity: sites at which the plants were observed.\n\n\nIf we use this information to normalize our data, we should end up with:\n\none tidy table for each entity observed, and\nadditional columns for identifying variables (such as site ID).\n\nHere’s how our normalized data would look like:\n\n\n\n\n\nNotice that each table also satisfies the tidy data principles.\nNormalizing data by separating it into multiple tables often makes researchers really uncomfortable. This is understandable! The person who designed this study collected all of these measurements for a reason - so that they could analyze the measurements together. Now that our site and plant information are in separate tables, how would we use site altitude as a predictor variable for species composition, for example? We will go over a solution in the next section.",
    "crumbs": [
      "Tidy Data"
    ]
  },
  {
    "objectID": "lecture_tidy_data.html#relational-data-models",
    "href": "lecture_tidy_data.html#relational-data-models",
    "title": "Tidy Data",
    "section": "7 Relational Data Models",
    "text": "7 Relational Data Models\n\nIt’s rare that a data analysis involves only a single table of data. Typically you have many tables of data, and you must combine them to answer the questions that you’re interested in. Collectively, multiple tables of data are called relational data because it is the relations, not just the individual datasets, that are important. (R for Data Science Chapter 13 Relational Data)\n\n\n7.1 What are relational data models?\nA relational data model is a way of encoding links between multiple tables in a database. A database organized following a relational data model is a relational database. A few of the advantages of using a relational data model are:\n\nEnabling powerful search and filtering\nAbility to handle large, complex data sets\nEnforcing data integrity\nDecreasing errors from redundant updates\n\nRelational data models are used by relational databases (like mySQL, MariaDB, Oracle, or Microsoft Access) to organize tables. However, you don’t have to be using a relational database or handling large and complex data to enjoy the benefits of using a relational data model.\nWhen working with relational data, we generally don’t work with tables separately. We will need to join the information from different tables to run our analysis. To join two or more tables we need to learn about keys.\n\n\n7.2 Primary and foreign keys\nThe main way in which relational data models encode relationships between different tables is by using keys. Keys are variables whose values uniquely identify observations. For tidy data, where variables and columns are equivalent, a column is a key if it has a different value in each row. This allows us to use keys as unique identifiers that reference particular observations and create links across tables.\nTwo types of keys are common within relational data models:\n\nPrimary Key: chosen key for a table, uniquely identifies each observation in the table,\nForeign Key: reference to a primary key in another table, used to create links between tables.\n\n\n\n7.3 Example\nOn our previously normalized data for plants and sites, let’s choose primary keys for these tables and then identify any foreign keys.\nPrimary keys\nFirst, notice that the columns ‘date’, ‘site’ and ‘sp_code’ cannot be primary keys because they have repeated values across rows. The columns ‘sp_height’ and ‘id’ both have different values in each row, so both are candidates for primary keys. However, the decimal values of ‘sp_height’ don’t make it as useful to use it to reference observations. So we chose ‘id’ as the primary key for this table.\nFor the sites table, all three columns could be keys. We chose ‘site’ as the primary key because it is the most succinct and it also allows us to link the sites table with the plants table.\nForeign keys\nThe ‘site’ column is the primary key of that table because it uniquely identifies each row of the table as a unique observation of a site. In the first table, however, the ‘site’ column is a foreign key that references the primary key from the second table. This linkage tells us that the first height measurement for the DAPU observation occurred at the site with the name Taku.\n\n\n\n\n\n\n\n7.4 Compound keys\n\n\nIt can also be the case that a variable is not a key, but by combining it with a second variable we get that the combined values uniquely identify the rows. This is called a\n\nCompound Key: a key that is made up of more than one variable.\n\nFor example, the ‘site’ and ‘sp_code’ columns in the plants table cannot be keys on their own, since each has repeated values. However, when we look at their combined values (1-DAPU, 1-DAMA, 2-DAMA, 2-DAPU) we see each row has a unique value. So ‘site’ and ‘sp_code’ together form a compound key.\n\nThere are also other types of keys, like a natural key or a surrogate key. Each type of key has advantages and disadvantages. You can read more about this in  this article.",
    "crumbs": [
      "Tidy Data"
    ]
  },
  {
    "objectID": "lecture_tidy_data.html#joins",
    "href": "lecture_tidy_data.html#joins",
    "title": "Tidy Data",
    "section": "8 Joins",
    "text": "8 Joins\nFrequently, analysis of data will require merging these separately managed tables back together. There are multiple ways to join the observations in two tables, based on how the rows of one table are merged with the rows of the other. Regardless of the join we will perform, we need to start by identifying the primary key in each table and how these appear as foreign keys in other tables.\nWhen conceptualizing merges, one can think of two tables, one on the left and one on the right.\n\n\n8.1 Inner Join\nAn INNER JOIN is when you merge the subset of rows that have matches in both the left table and the right table.\n\n\n\n8.2 Left Join\nA LEFT JOIN takes all of the rows from the left table, and merges on the data from matching rows in the right table. Keys that don’t match from the left table are still provided with a missing value (na) from the right table.\n\n\n\n8.3 Right Join\nA RIGHT JOIN is the same as a left join, except that all of the rows from the right table are included with matching data from the left, or a missing value. Notice that left and right joins can ultimately be the same depending on the positions of the tables\n\n\n\n8.4 Full Outer Join\nFinally, a FULL OUTER JOIN includes all data from all rows in both tables, and includes missing values wherever necessary.\n\nSometimes people represent joins as Venn diagrams, showing which parts of the left and right tables are included in the results for each join. This representation is useful, however, they miss part of the story related to where the missing value comes from in each result.\n\n\n\nImage source: R for Data Science, Wickham & Grolemund.\n\n\nWe suggest reading the Relational Data chapter in the “R for Data Science” book  for more examples and best practices about joins.\n\n\n8.5 Entity-Relationship models\nAn Entity-Relationship model (E-R model), also known as an E-R diagram, is a way to draw a compact diagram that reflects the structure and relationships of the tables in a relational database. These can be particularly useful for big databases that have many tables and complex relationships between them.\nWe will explain the steps to drawing a simplified E-R model with our previous plants and sites tables.\nStep 1: Identify the entities in the relational database and add each one in a box. In our case, entities are [plants] and [sites], since we are gathering observations about both of these.\n\n\n\n\n\nStep 2: Add variables for each entity and identify keys. Add the variables as a list inside each box. Then, identify the primary and foreign keys in each of the boxes. To visualize this, we have indicated\n\nthe  primary key  (of each entity) in  red  and\nany  foreign keys  in  blue .\n\n\n\n\n\n\nStep 3: Add relationships between entities.\n\nDraw a line between the boxes of any two entities that have a relationship.\nIdentify which box has the primary key of the other as a foreign key. Let’s call the box that has the foreign key [box1] and the other box [box2]. Using the previous diagram we can see that “site” is the primary key of [sites] and appears as a foreign key in [plants]. So [plants] is [box1] and [sites] is [box2].\nAdd a word describing how [box1] is related to [box2] above the line connecting the two boxes. So, for example, we need to describe how [plants] is related to [sites]. The relation is “a plant is located in a site”, so we write “located” above the line indicating the relationship between [plants] and [sites].\n\n\n\n\n\n\nStep 4: Add cardinality to every relationship in the diagram. At this step we want to quantify how many items in an entity are related to another entity. This is easiest if we reuse the description we found in the previous step. For example, “a plant is located in one site”. Then we add the symbol for “one” at the end of the line going from [plants] to [sites].\n\n\n\n\n\nTo finish, we also indicate how many plants are related to a single site. Since “a site has many plants”, we add the symbol for “many” at the end of the line going from [sites] to [plants]\n\n\n\n\n\nThat’s it!\n\n8.5.1 EDR Crow’s Foot\nThe symbols we used at the end of the lines are called ERD “crow’s foot”. You can see all the existing ones together with an example in the next diagram.\n\n\n\n\n\n\n\nNote\n\n\n\nIf you need to produce a publishable E-R model such as the one above,  Mermaid  is a great option. Read more about how to use this tool to create diagrams  here .",
    "crumbs": [
      "Tidy Data"
    ]
  },
  {
    "objectID": "lecture_tidy_data.html#best-practices-summary",
    "href": "lecture_tidy_data.html#best-practices-summary",
    "title": "Tidy Data",
    "section": "9 Best Practices Summary",
    "text": "9 Best Practices Summary\nThis is a summary of what we have covered, and some extra advice!\nThe tidy data principles are:\n\nEvery column is a variable.\nEvery row is an observation.\nEvery cell is a single value.\n\nIn normalized data we organize data so that :\n\nWe have separate tables for each type of entity measured\nObservations (rows) are all unique\nEach column represents either an identifying variable or a measured variable\nEach table follows the tidy data principles\n\nCreating relational data models by assigning primary and foreign keys to each table allows us to maintain relationships between separate normalized tables. Choose the primary key for each table based on your understanding of the data and take efficiency into account. Once you choose a column as the primary key, make sure that all the values in that column are there!\nFor a big relational database, an Entity-Relationship model can be an effective way to explain how different tables and their keys are related to each other. If we need to merge tables we can do it using different types of joins.",
    "crumbs": [
      "Tidy Data"
    ]
  },
  {
    "objectID": "lecture_tidy_data.html#more-on-data-management",
    "href": "lecture_tidy_data.html#more-on-data-management",
    "title": "Tidy Data",
    "section": "10 More on Data Management",
    "text": "10 More on Data Management\nTidy data is one very important step to data management best practices. However there is more to consider. Here we provide some extra advice from a great paper called  ‘Some Simple Guidelines for Effective Data Management’.\n\nDesign tables to add rows, not columns\nUse a scripted program (like R!)\nNon-proprietary file formats are preferred (eg: csv, txt)\nKeep a raw version of data\nUse descriptive files and variable names (without spaces!)\nInclude a header line in your tabular data files\nUse plain ASCII text\n\nIn the Cleaning & Wrangling chapter we will cover more best practices for cleaning irregular and missing data and how to implement them using R.",
    "crumbs": [
      "Tidy Data"
    ]
  },
  {
    "objectID": "lecture_tidy_data.html#activity",
    "href": "lecture_tidy_data.html#activity",
    "title": "Tidy Data",
    "section": "11 Activity",
    "text": "11 Activity\n\n\n\n\n\n\n\n\nTipTidy data, keys and joins\n\n\n\n\nGet together in pairs or small groups\nObtain materials from instructors including activity handout and blank paper(s).\nFollow instructions in activity handout.",
    "crumbs": [
      "Tidy Data"
    ]
  },
  {
    "objectID": "index.html#why-should-i-join",
    "href": "index.html#why-should-i-join",
    "title": "About this series",
    "section": "1 Why Should I Join?",
    "text": "1 Why Should I Join?\nBy popular request, I’m going to lead a series of workshops about working with data. These are based on stellar training materials developed by the National Center for Ecological Analysis and Synthesis (NCEAS), who are arguably the experts at teaching this stuff. We will cover practical ways to make life easier for Future You and keep projects (mostly) under control.\nThis is an immersion series in R programming for environmental data science, focusing on how to leverage data science tools to:\n\nincrease your capacity to collaborate with your team,\ncreate reproducible workflows,\nand learn best practices for open science.",
    "crumbs": [
      "About this series"
    ]
  },
  {
    "objectID": "index.html#nceas-expertise",
    "href": "index.html#nceas-expertise",
    "title": "About this series",
    "section": "2 NCEAS Expertise",
    "text": "2 NCEAS Expertise\nThe National Center for Ecological Analysis and Synthesis (NCEAS), a research affiliate of UCSB, is a leading expert on interdisciplinary data science and works collaboratively to answer the world’s largest and most complex questions. The NCEAS approach leverages existing data and employs a team science philosophy to squeeze out all potential insights and solutions efficiently - this is called synthesis science.\nNCEAS has over 25 years of success with this model among working groups and environmental professionals. We are excited to pass along skills, workflows, mindsets learn throughout the years.",
    "crumbs": [
      "About this series"
    ]
  },
  {
    "objectID": "index.html#about-these-materials",
    "href": "index.html#about-these-materials",
    "title": "About this series",
    "section": "3 About these materials",
    "text": "3 About these materials\nThese written materials are the result of a continuous and collaborative effort at NCEAS to help researchers make their work more transparent and reproducible. This work began in the early 2000’s, and reflects the expertise and diligence of many, many individuals. The primary authors are listed in the citation below, with additional contributors recognized for their role in developing previous iterations of these or similar materials.\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\nCitation: Camila Vargas Poulsen, Casey O’Hara, Shayna Sura (2024), NCEAS coreR for Delta Science Program, October 2024, NCEAS Learning Hub.\nAdditional contributors: Ben Bolker, Amber E. Budden, Julien Brun, Samantha Csik, Halina Do-Linh, Natasha Haycock-Chavez, S. Jeanette Clark, Julie Lowndes, Stephanie Hampton, Matt Jone, Samanta Katz, Erin McLean, Bryce Mecum, Deanna Pennington, Karthik Ram, Jim Regetz, Tracy Teal, Daphne Virlar-Knight, Leah Wasser.",
    "crumbs": [
      "About this series"
    ]
  },
  {
    "objectID": "r_rproject_setup.html",
    "href": "r_rproject_setup.html",
    "title": "2 R Project Setup",
    "section": "",
    "text": "TipLearning Objectives\n\n\n\n\nPractice creating an R Project\nOrganize an R Project for effective project management\nUnderstand how to move in an R Project using paths and working directories",
    "crumbs": [
      "2 R Project Setup"
    ]
  },
  {
    "objectID": "r_rproject_setup.html#create-an-r-project",
    "href": "r_rproject_setup.html#create-an-r-project",
    "title": "2 R Project Setup",
    "section": "1 Create an R Project",
    "text": "1 Create an R Project\nAn R project is tied to a directory on your local computer, and makes organizing your work and collaborating with others easier.\nThe Big Idea: using an R project is a reproducible research best practice because it bundles all your work within a working directory. Consider your current data analysis workflow. Where do you import you data? Where do you clean and wrangle it? Where do you create graphs, and ultimately, a final report? Are you going back and forth between multiple software tools like Microsoft Excel, R, and Google Docs? Using an R project (and the tools in R) will consolidate this process because it can all be done (and updated) in using one software tool, RStudio, and within one R project.\n\n\n\n\n\n\nTipR Project Setup\n\n\n\n\nIn the “File” menu, select “New Project”\nClick “New Directory”\nClick “New Project”\nUnder “Directory name” type: training_{USERNAME} (i.e. training_lopazanski)\nLeave “Create Project as subdirectory of:” set to the location where you want to save the project on your computer.\nClick “Create Project”\n\nRStudio should open your new project automatically after creating it. One way to check this is by looking at the top right corner and checking for the project name.",
    "crumbs": [
      "2 R Project Setup"
    ]
  },
  {
    "objectID": "r_rproject_setup.html#organizing-an-r-project",
    "href": "r_rproject_setup.html#organizing-an-r-project",
    "title": "2 R Project Setup",
    "section": "2 Organizing an R Project",
    "text": "2 Organizing an R Project\nThe next step is to populate that project with relevant directories. There are many tools that can do this automatically (e.g., rrtools or usethis::create_package()). The goal is to organize your project so that it is a compendium of your research. This means that the project has all of the digital parts needed to replicate your analysis, like code, figures, the manuscript, and data.\nSome common directories are:\n\n\n\ndata: where we store data (often contains subdirectories for raw, processed, and metadata data)\nscripts: has all scripts where you clean and wrangle data and run your analysis\nplots or figs: generated plots, graphs, and figures\ndocs: summaries or reports of analysis or other relevant project information\n\nDirectory organization varies from project to project, but the goal is to create a well-organized project for both reproducibility and collaboration.\n\n\n\n\n\n\n\n\n\n\nTipProject Sub-directories\n\n\n\nFor this series we will create 3 folders (directories) in our training_{USERNAME} Rproject.\nIn the files pane in RStudio (bottom right), click on the New Folder button (with a green circle and plus sign) and create 3 new folders: data, plots, scripts.",
    "crumbs": [
      "2 R Project Setup"
    ]
  },
  {
    "objectID": "r_rproject_setup.html#moving-in-an-r-project-using-paths-working-directories",
    "href": "r_rproject_setup.html#moving-in-an-r-project-using-paths-working-directories",
    "title": "2 R Project Setup",
    "section": "3 Moving in an R Project using Paths & Working Directories",
    "text": "3 Moving in an R Project using Paths & Working Directories\n\nNow that we have a project created (we know it’s an R Project because we see a .Rproj file in our Files pane), we can move files within that project. We do this using paths.\nThere are two types of paths in computing: absolute paths and relative paths.\n\nAbsolute paths always starts with the root of your file system and locates files from there. The absolute path to my project directory is: /home/lopazanski/github/training_lopazanski\nRelative paths start from some location in your file system that is below the root. Relative paths are combined with the path of that location to locate files on your system. R (and some other languages like MATLAB) refer to the location where the relative path starts as our working directory.\n\nRStudio projects automatically set the working directory to the directory of the project. This means that you can reference files from within the project without worrying about where the project directory itself is. If I want to read in a file from the data directory within my project, I can simply type read.csv(\"data/samples.csv\") as opposed to read.csv(\"/home/lopazanski/github/training_lopazanski/data/samples.csv\").\nThis is not only convenient for you, but also when working collaboratively. We will talk more about this later, but if Joe makes a copy of my R project that I have published on GitHub, and I am using relative paths, he can run my code exactly as I have written it, without going back and changing /home/lopazanski/github/training_lopazanski/data/samples.csv to /home/morton/github/training_morton/data/samples.csv.\nNote that once you start working in projects you should basically never need to run the setwd() command. If you are in the habit of doing this, stop and take a look at where and why you do it. Could Leveraging the working directory concept of R projects could likely eliminate this need.\nSimilarly, think about how you work with absolute paths. You could likely leverage the working directory of your R project to replace these with relative paths and make your code more portable.",
    "crumbs": [
      "2 R Project Setup"
    ]
  },
  {
    "objectID": "r_practice_tidy_data_joins.html",
    "href": "r_practice_tidy_data_joins.html",
    "title": "Practice Session: Joins",
    "section": "",
    "text": "TipLearning Objectives\n\n\n\n\nPractice joining tables together\nPractice identifying primary and foreign keys\nPractice using common cleaning and wrangling functions",
    "crumbs": [
      "Practice Session: Joins"
    ]
  },
  {
    "objectID": "r_practice_tidy_data_joins.html#about-the-data",
    "href": "r_practice_tidy_data_joins.html#about-the-data",
    "title": "Practice Session: Joins",
    "section": "About the data",
    "text": "About the data\nThese exercises will be using bird survey data collected from the central Arizona-Phoenix metropolitan area by Arizona State University researchers [@warren2021].",
    "crumbs": [
      "Practice Session: Joins"
    ]
  },
  {
    "objectID": "r_practice_tidy_data_joins.html#exercise-1-practice-joins",
    "href": "r_practice_tidy_data_joins.html#exercise-1-practice-joins",
    "title": "Practice Session: Joins",
    "section": "Exercise 1: Practice Joins",
    "text": "Exercise 1: Practice Joins\n\n\n\n\n\n\nTipSetup\n\n\n\n\nMake sure you’re in the right project (training_{USERNAME}) and use the Git workflow by Pulling to check for any changes in the remote repository (aka repository on GitHub).\nCreate a new Quarto Document.\n\nTitle it “R Practice: Tidy Data and Joins”.\nSave the file and name it “r-practice-tidy-data-joins” in your scripts folder.\n\n\nNote: Double check that you’re in the right project. Where in RStudio can you check where you are?\n\nLoad the following libraries at the top of your Quarto Document.\n\n\nlibrary(readr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(here)\n\nhere() starts at /Users/lopazanski/Documents/github/duke_data_sci\n\nlibrary(lubridate) # for bonus question\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n# Quick question: Do you get a message after loading the libraries? What is it telling you? Talk to your neighbor about it or write a note in your qmd.\n\n\nObtain data from the EDI Data Portal Ecological and social interactions in urban parks: bird surveys in local parks in the central Arizona-Phoenix metropolitan area. Download the following files:\n\n\n52_pp52_birds_1.csv\n52_pp52_surveys_1.csv\n52_pp52_sites_1.csv\n52_pp52_taxalist_1.csv\n\nNote: It’s up to you on how you want to download and load the data! You can either use the download links (obtain by right-clicking the “Download” button and select “Copy Link Address” for each data entity) or manually download the data and then upload the files to RStudio server.\n\nOrganize your Quarto Document in a meaningful way. Organization is personal - so this is up to you! Consider the different ways we’ve organized previous files using: headers, bold text, naming code chunks, comments in code chunks. What is most important is organizing and documenting the file so that your future self (or if you share this file with others!) understands it as well as your current self does right now.\nUse the Git workflow. After you’ve set up your project and uploaded your data go through the workflow: Stage (add) -&gt; Commit -&gt; Pull -&gt; Push\n\nNote: You also want to Pull when you first open a project.",
    "crumbs": [
      "Practice Session: Joins"
    ]
  },
  {
    "objectID": "r_practice_tidy_data_joins.html#read-in-the-data",
    "href": "r_practice_tidy_data_joins.html#read-in-the-data",
    "title": "Practice Session: Joins",
    "section": "1 Read in the data",
    "text": "1 Read in the data\n\n\n\n\n\n\nNoteQuestion 1\n\n\n\nRead in the data and store the data frames as bird_observations, sites, surveys, and taxalist (it should be clear from the raw file names which is which).\n\n\n\n\nRows: 40425 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): site_id, species_id, distance, notes, direction\ndbl (4): survey_id, bird_count, seen, heard\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 2004 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): site_id, observer, wind_dir, notes\ndbl  (4): survey_id, wind_speed, air_temp, cloud_cover\nlgl  (1): temp_units\ndttm (3): survey_date, time_start, time_end\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 221 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): site_id, park_code, park_district, park_name, point_code\nlgl (2): point_location, park_acreage\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 259 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): species_id, common_name\ndbl (1): asu_itis\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n# read in data from the data directory after manually downloading data \nbird_observations &lt;- read_csv(here::here(\"data/52_pp52_birds_1.csv\"))\nsurveys &lt;- read_csv(here::here(\"data/52_pp52_surveys_1.csv\"))\nsites &lt;- read_csv(here::here(\"data/52_pp52_sites_1.csv\"))\ntaxalist &lt;- read_csv(here::here(\"data/52_pp52_taxalist_1.csv\"))",
    "crumbs": [
      "Practice Session: Joins"
    ]
  },
  {
    "objectID": "r_practice_tidy_data_joins.html#get-familiar-with-the-data",
    "href": "r_practice_tidy_data_joins.html#get-familiar-with-the-data",
    "title": "Practice Session: Joins",
    "section": "2 Get familiar with the data",
    "text": "2 Get familiar with the data\n\n\n\n\n\n\nNoteQuestion 2a\n\n\n\nWhat functions can you use to explore the data you just read in? Think about which functions we’ve been using to explore the structure of the data frame, information about columns, unique observations, etc. Tip: run View(name_of_your_data_frame) in the console to see data in a spreadsheet-style viewer.\n\n\n\n# returns dimensions of the dataframe by number of rows and number of cols\ndim(bird_observations)\n\n[1] 40425     9\n\n# returns the top six rows of the dataframe\nhead(bird_observations)\n\n# A tibble: 6 × 9\n  survey_id site_id species_id distance bird_count notes  seen heard direction\n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    \n1       144 LI-S    HOSP       5-10              4 &lt;NA&gt;      1     1 NE       \n2       145 LI-W    HOSP       20-40            10 &lt;NA&gt;      0     1 E        \n3       145 LI-W    AUWA       20-40             2 &lt;NA&gt;      0     1 SE       \n4       145 LI-W    RODO       FT                2 &lt;NA&gt;      1     0 E        \n5       145 LI-W    GTGR       &gt;40               2 &lt;NA&gt;      0     1 NE       \n6       145 LI-W    WCSP       20-40             3 &lt;NA&gt;      0     1 N        \n\n# returns all the columns and some info about the cols\nglimpse(bird_observations)\n\nRows: 40,425\nColumns: 9\n$ survey_id  &lt;dbl&gt; 144, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145,…\n$ site_id    &lt;chr&gt; \"LI-S\", \"LI-W\", \"LI-W\", \"LI-W\", \"LI-W\", \"LI-W\", \"LI-W\", \"LI…\n$ species_id &lt;chr&gt; \"HOSP\", \"HOSP\", \"AUWA\", \"RODO\", \"GTGR\", \"WCSP\", \"WCSP\", \"GT…\n$ distance   &lt;chr&gt; \"5-10\", \"20-40\", \"20-40\", \"FT\", \"&gt;40\", \"20-40\", \"20-40\", \"F…\n$ bird_count &lt;dbl&gt; 4, 10, 2, 2, 2, 3, 3, 2, 2, 3, 1, 10, 3, 1, 6, 6, 20, 12, 2…\n$ notes      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ seen       &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,…\n$ heard      &lt;dbl&gt; 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,…\n$ direction  &lt;chr&gt; \"NE\", \"E\", \"SE\", \"E\", \"NE\", \"N\", \"E\", \"E\", \"S\", \"E\", \"NE\", …\n\n# similar to glimpse but returns some summary statistics about the cols\nsummary(bird_observations)\n\n   survey_id      site_id           species_id          distance        \n Min.   :   1   Length:40425       Length:40425       Length:40425      \n 1st Qu.: 570   Class :character   Class :character   Class :character  \n Median :1028   Mode  :character   Mode  :character   Mode  :character  \n Mean   :1043                                                           \n 3rd Qu.:1550                                                           \n Max.   :2001                                                           \n                                                                        \n   bird_count          notes                seen            heard       \n Min.   :   1.000   Length:40425       Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:   1.000   Class :character   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :   2.000   Mode  :character   Median :1.0000   Median :0.0000  \n Mean   :   2.938                      Mean   :0.8463   Mean   :0.4967  \n 3rd Qu.:   3.000                      3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1000.000                      Max.   :1.0000   Max.   :1.0000  \n NA's   :33                                                             \n  direction        \n Length:40425      \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\n# returns column names \nnames(bird_observations)\n\n[1] \"survey_id\"  \"site_id\"    \"species_id\" \"distance\"   \"bird_count\"\n[6] \"notes\"      \"seen\"       \"heard\"      \"direction\" \n\n# returns unique values in a column. In this case we can see all the different bird species IDs\nunique(bird_observations$species_id)\n\n  [1] \"HOSP\" \"AUWA\" \"RODO\" \"GTGR\" \"WCSP\" \"MODO\" \"NOMO\" \"EUST\" \"ANHU\" \"CBTH\"\n [11] \"INDO\" \"GIWO\" \"HOFI\" \"VERD\" \"GHJU\" \"ORJU\" \"KILL\" \"BCHU\" \"ABTO\" \"CACW\"\n [21] \"WEME\" \"CORA\" \"NOHA\" \"NOFL\" \"PYRR\" \"CANW\" \"GIFL\" \"SCJU\" \"BRCR\" \"RCKI\"\n [31] \"COHU\" \"BGGN\" \"SAPH\" \"AMKE\" \"HAHA\" \"HOLA\" \"LOSH\" \"AMGO\" \"BEVI\" \"OCWA\"\n [41] \"BRSP\" \"COYE\" \"SPTO\" \"WBNU\" \"noca\" \"BTSP\" \"ROWR\" \"PHAI\" \"RWBL\" \"FEHA\"\n [51] \"COHA\" \"RTHA\" \"ATFL\" \"BHCO\" \"BRBL\" \"UNDO\" \"SOVI\" \"MALL\" \"SSHA\" \"CEDW\"\n [61] \"AMRO\" \"WEBL\" \"GAQU\" \"LEWO\" \"unwa\" \"CAGO\" \"LEGO\" \"broc\" \"WWDO\" \"COFL\"\n [71] \"SOSP\" \"NRWS\" \"GBHE\" \"WEKI\" \"NAWA\" \"LBWO\" \"BTGN\" \"YWAR\" \"UDEJ\" \"BCNH\"\n [81] \"BTYW\" \"LUWA\" \"CLSW\" \"CAKI\" \"UNTA\" \"PFLB\" \"UNHA\" \"HRSH\" \"BETH\" \"UNWO\"\n [91] \"RSFL\" \"WIWA\" \"WEFL\" \"unhu\" \"GRRO\" \"ECDO\" \"BROC\" \"HOOR\" \"NOCA\" \"TOWA\"\n[101] \"YHBL\" \"WTSW\" \"UNTH\" \"RUHU\" \"WETA\" \"AMCO\" \"LENI\" \"UYRW\" \"LASP\" \"RNSA\"\n[111] \"UNFL\" \"BLPH\" \"MGWA\" \"TUVU\" \"UNBL\" \"TRES\" \"UNSP\" \"GREG\" \"SNEG\" \"UNSW\"\n[121] \"CHSP\" \"WAVI\"\n\n\n\n\n\n\n\n\nNoteQuestion 2b\n\n\n\nWhat are the primary and foreign keys for the tables bird_observations and taxalist? Recall that a primary key is a unique identifier for each observed entity, one per row. And a foreign key references to a primary key in another table (linkage).\nHint: First identify the primary keys for all the tables, then identify the foreign keys.\n\n\n\n\nAnswer\n\n\nbird_observations: Primary key is a compound key made up of survey_id, site_id, and species_id. The foreign key is species_id.\ntaxalist: Primary key is species_id and does not have a foreign key that match the primary key in bird_observations.\n\nHowever, we could join bird_observations and taxalist by species_id, but depending on the type of join some values would be droped or NAs would be introduce in the resulting data frame.",
    "crumbs": [
      "Practice Session: Joins"
    ]
  },
  {
    "objectID": "r_practice_tidy_data_joins.html#create-a-subset-of-bird_observations",
    "href": "r_practice_tidy_data_joins.html#create-a-subset-of-bird_observations",
    "title": "Practice Session: Joins",
    "section": "3 Create a subset of bird_observations",
    "text": "3 Create a subset of bird_observations\n\n\n\n\n\n\nNoteQuestion 3\n\n\n\nWrite code to create a subset of bird_observations called birds_subset that only contains observations for birds with species id BHCO and RWBL, and from sites with site ID LI-W and NU-C.\nHint: What function do you use to subset data by rows?\n\n\n\nbirds_subset &lt;- bird_observations %&gt;% \n  filter(species_id %in% c(\"BHCO\", \"RWBL\")) %&gt;% \n  filter(site_id %in% c(\"LI-W\", \"NU-C\"))",
    "crumbs": [
      "Practice Session: Joins"
    ]
  },
  {
    "objectID": "r_practice_tidy_data_joins.html#use-left_join-to-merge-birds_subset-with-the-tables-sites",
    "href": "r_practice_tidy_data_joins.html#use-left_join-to-merge-birds_subset-with-the-tables-sites",
    "title": "Practice Session: Joins",
    "section": "4 Use left_join() to merge birds_subset with the tables sites",
    "text": "4 Use left_join() to merge birds_subset with the tables sites\n\n\n\n\n\n\nNoteQuestion 4a\n\n\n\nFirst, answer: what do you expect the outcome data frame when doing left_join() between birds_subset and sites to look like? What observations do you expect in the outcome data frame.\nYou can use paper to draw if that helps you or talk to your neighbor. Write down the steps and expected outcome in your Quarto Document.\n\n\n\n\nAnswer\n\nI expect to see all columns and all observations from birds_subset and from sites, I expect to see the columns park_code, park_district, park-name, point_code, point_location and park_acreage and only observations for NU-C and LI-W because those are the only site_id values in birds_subset and in a left join only the observations matching the left table (in this case, birds_subset is the left table) will be kept.\n\n\n\n\n\n\n\nNoteQustion 4b\n\n\n\nUse a left join to update birds_subset so that it also includes sites information. For each join, include an explicit argument saying which key you are joining by (even if it will just assume the correct one for you). Store the updated data frame as birds_left. Make sure to look at the output - is what it contains consistent with what you expected it to contain?\n\n\n\n# syntax using pipe\nbirds_left &lt;- birds_subset %&gt;% \n  left_join(y = sites, by = \"site_id\")\n# don't see x = birds_subset here because piping in birds_subset means it automatically assumes birds_subset as x.\n\n# syntax without pipe\nbirds_left &lt;- left_join(x = birds_subset, y = sites, by = \"site_id\")",
    "crumbs": [
      "Practice Session: Joins"
    ]
  },
  {
    "objectID": "r_practice_tidy_data_joins.html#use-full_join-to-merge-birds_subset-and-sites-tables",
    "href": "r_practice_tidy_data_joins.html#use-full_join-to-merge-birds_subset-and-sites-tables",
    "title": "Practice Session: Joins",
    "section": "5 Use full_join() to merge birds_subset and sites tables",
    "text": "5 Use full_join() to merge birds_subset and sites tables\n\n\n\n\n\n\nNoteQuestion 5a\n\n\n\nFirst, answer: what do you expect a full_join() between birds_subset and sites to contain? Write this in your Quarto Document or tell a neighbor.\n\n\n\n\nAnswer\n\nI expect to see all columns and all observations from birds_subset and all columns and all observations from sites to be merged into one data frame because in a full join everything is kept. NA values could be introduced.\n\n\n\n\n\n\n\nNoteQuestions 5b\n\n\n\nWrite code to full_join() the birds_subset and sites data into a new object called birds_full. Explicitly include the variable you’re joining by. Look at the output. Is it what you expected?\n\n\n\n# syntax using pipe\nbirds_full &lt;- birds_subset %&gt;% \n  full_join(y = sites, by = \"site_id\")\n\n# syntax without pipe\nbirds_full &lt;- full_join(x = birds_subset, y = sites, by = \"site_id\")",
    "crumbs": [
      "Practice Session: Joins"
    ]
  },
  {
    "objectID": "r_practice_tidy_data_joins.html#use-inner_join-to-merge-birds_subset-and-taxalist-data",
    "href": "r_practice_tidy_data_joins.html#use-inner_join-to-merge-birds_subset-and-taxalist-data",
    "title": "Practice Session: Joins",
    "section": "6 Use inner_join() to merge birds_subset and taxalist data",
    "text": "6 Use inner_join() to merge birds_subset and taxalist data\n\n\n\n\n\n\nNoteQuestion 6a\n\n\n\nFirst, answer: what do you expect an inner_join() between birds_subset and taxalist to contain? Write this in your Quarto Document or tell a neighbor.\n\n\n\n\nAnswer\n\nI expect to only have data merge together based on species_id and since there is only BHCO and RWBL in birds_subset then I will only retain data related to those two species. I will also expect to see the columns from taxalist: common_name and asu_itis to be merged into the joined table.\n\n\n\n\n\n\n\nNoteQuestion 6b\n\n\n\nWrite code to inner_join() the birds_subset and taxalist, called birds_inner. Include an argument for what variable you’ll be joining by. Make sure you check the output.\n\n\n\n# syntax using pipe\nbirds_inner &lt;- birds_subset %&gt;% \n  inner_join(y = taxalist, by = \"species_id\")\n\n# syntax without pipe\nbirds_inner &lt;- inner_join(x = birds_subset, y = taxalist, by = \"species_id\" )\n\n\n\n\n\n\n\nNoteQuestion 6c\n\n\n\nWhat would you get if instead of inner_join() you’d used left_join() for this example? Write code for the left join and check.\n\n\n\n# syntax using pipe\nbirds_inner_left &lt;- birds_subset %&gt;% \n  left_join(y = taxalist, by = \"species_id\")\n\n# syntax without pipe\nbirds_inner_left &lt;- left_join(x = birds_subset, y = taxalist, by = \"species_id\")\n\n\n\n\n\n\n\nNoteQuestion 6d\n\n\n\nWhy does that make sense for this scenario? In what case would you expect the outcome to differ from an inner_join()? Write this in your Quarto Document or tell a neighbor.\n\n\n\n\nAnswer\n\nYou have the same resulting data set regardless of using inner_join() or left_join() to merge bird_subset and taxalist. The reasons for this are:\n\ninner_join() keeps only the rows (observations) that have a matching key across both data sets - here, species_id is our key, and the only rows that match across both data sets are those where species_id equals BHCO or RWBL\nleft_join() keeps all rows from the left table (in our case, the left table is birds_subset) and merges on data with matching keys (species_id) on the right (here, the right table is taxalist). Because our left data set (birds_subset) only contains species_ids equal to BHCO or RWBL, only rows with those species will be kept from the right data set (taxalist)\n\nYou’d expect the outcome to differ from an inner_join() if birds_subset contained an observation with a species_id that was not found in taxalist. If there was an observation of a species_id in birds_subset that was not in taxalist, then that observation would be kept, and NAs would be assigned to the common_name and asu_itis columns for that observations",
    "crumbs": [
      "Practice Session: Joins"
    ]
  },
  {
    "objectID": "r_practice_tidy_data_joins.html#exercise-2-practice-wrangling-joining-data",
    "href": "r_practice_tidy_data_joins.html#exercise-2-practice-wrangling-joining-data",
    "title": "Practice Session: Joins",
    "section": "Exercise 2: Practice Wrangling & Joining Data",
    "text": "Exercise 2: Practice Wrangling & Joining Data",
    "crumbs": [
      "Practice Session: Joins"
    ]
  },
  {
    "objectID": "r_practice_tidy_data_joins.html#wrangle-bird_observations-data-and-merge-the-data-with-all-the-other-tables-sites-surveys-and-taxalist",
    "href": "r_practice_tidy_data_joins.html#wrangle-bird_observations-data-and-merge-the-data-with-all-the-other-tables-sites-surveys-and-taxalist",
    "title": "Practice Session: Joins",
    "section": "7 Wrangle bird_observations data and merge the data with all the other tables (sites, surveys, and taxalist)",
    "text": "7 Wrangle bird_observations data and merge the data with all the other tables (sites, surveys, and taxalist)\n\n\n\n\n\n\nNoteQuestion 7a\n\n\n\nStarting with your object bird_observations, rename the notes column to bird_obs_notes (so this doesn’t conflict with notes in the surveys table).\n\n\n\nbird_observations &lt;- bird_observations %&gt;% \n  rename(bird_obs_notes = notes)\n\n\n\n\n\n\n\nNoteQuestion 7b\n\n\n\n\nCreate a subset that contains all observations in the birds_observations data frame,\nthen join the taxalist, sites and surveys tables to it,\nand finally limit to only columns survey_date, common_name, park_name, bird_count, and observer.\n\nHint: What function do you use to subset data by columns?\n\n\n\nbird_obs_subset &lt;- bird_observations %&gt;% \n  full_join(y = taxalist, by = \"species_id\") %&gt;% \n  full_join(y = sites, by = \"site_id\") %&gt;% \n  full_join(y = surveys, by = c(\"site_id\", \"survey_id\")) %&gt;%  \n  select(survey_date, common_name, park_name, bird_count, observer)",
    "crumbs": [
      "Practice Session: Joins"
    ]
  },
  {
    "objectID": "r_practice_tidy_data_joins.html#explore-observer-data-and-fix-the-values-within-this-column-so-that-all-values-are-in-the-same-format",
    "href": "r_practice_tidy_data_joins.html#explore-observer-data-and-fix-the-values-within-this-column-so-that-all-values-are-in-the-same-format",
    "title": "Practice Session: Joins",
    "section": "8 Explore observer data and fix the values within this column so that all values are in the same format",
    "text": "8 Explore observer data and fix the values within this column so that all values are in the same format\n\n\n\n\n\n\nNoteQuestion 8a\n\n\n\nContinuing with bird_obs_subset, first use unique() to see the different unique values in the column observer. How many observers are there? Which value is unlike the others?\n\n\n\nunique(bird_obs_subset$observer)\n\n[1] \"B. Rambo\"   \"J. Lemmer\"  \"D. Stuart\"  \"C. Putnam\"  \"S. Lerman\" \n[6] \"Josh Burns\" NA          \n\n\n\n\n\n\n\n\nNoteQuestion 8b\n\n\n\nReplace “Josh Burns” with a format that matches the other observer names. Then use unique() again to check your work.\nHint: What function do you use when you are making a change to an entire column?\n\n\n\nbird_obs_subset &lt;- bird_obs_subset %&gt;% \n  mutate(observer = if_else(condition = observer == \"Josh Burns\", \n                            true = \"J. Burns\", \n                            false = observer))\n\nunique(bird_obs_subset$observer)\n\n[1] \"B. Rambo\"  \"J. Lemmer\" \"D. Stuart\" \"C. Putnam\" \"S. Lerman\" \"J. Burns\" \n[7] NA         \n\n\n\n\n\n\n\n\nImportantSave your work and dont’s forget the Git and GitHub Workflow\n\n\n\nAfter you’ve completed the exercises or reached a significant stopping point, use the workflow: Stage (add) -&gt; Commit -&gt; Pull -&gt; Push",
    "crumbs": [
      "Practice Session: Joins"
    ]
  },
  {
    "objectID": "r_practice_tidy_data_joins.html#bonus-use-a-new-package-lubridate-to-wrangle-the-date-data-and-find-the-total-number-of-birds-by-park-and-month",
    "href": "r_practice_tidy_data_joins.html#bonus-use-a-new-package-lubridate-to-wrangle-the-date-data-and-find-the-total-number-of-birds-by-park-and-month",
    "title": "Practice Session: Joins",
    "section": "9 Bonus: Use a new package lubridate to wrangle the date data and find the total number of birds by park and month",
    "text": "9 Bonus: Use a new package lubridate to wrangle the date data and find the total number of birds by park and month\nHint: How do you learn about a new function or package?\n\n\n\n\n\n\nNoteBonus Question(s)\n\n\n\n\nUse lubridate::month() to add a new column to bird_obs_subset called survey_month, containing only the month number. Then, convert the month number to a factor (again within mutate()).\nUse dplyr::relocate() to move the new survey_month column to immediately after the survey_date column. You can do this in a separate code chunk, or pipe straight into it from your existing code.\nFilter to only include parks Lindo, Orme, Palomino, and Sonrisa.\nFind the total number of birds observed by park and month (Hint: You can use group_by() and summarize()).\n\n\n\n\nbird_obs_subset &lt;- bird_obs_subset %&gt;% \n  mutate(survey_month = lubridate::month(survey_date)) %&gt;% \n  mutate(survey_month = as.factor(survey_month)) %&gt;% \n  dplyr::relocate(survey_month, .after = survey_date) %&gt;% \n  filter(park_name %in% c(\"Lindo\", \"Orme\", \"Palomino\", \"Sonrisa\")) %&gt;% \n  group_by(park_name, survey_month) %&gt;% \n  summarize(tot_bird_count_month = n())\n\n`summarise()` has grouped output by 'park_name'. You can override using the\n`.groups` argument.\n\n\nTake a look at your final data frame. Does it give you the outcome you expected? Is it informative? How would you improve this wrangling process?",
    "crumbs": [
      "Practice Session: Joins"
    ]
  },
  {
    "objectID": "r_git_install_guide.html",
    "href": "r_git_install_guide.html",
    "title": "Installing R and Git on Your Computer",
    "section": "",
    "text": "To install R, visit cloud.r-project.org to download the most recent version for your operating system. The latest release is version 4.5 ([Not] Part in a Rumble, released 2025-10-31). Note: As long as you have version 4.4 or higher you are set for this series.\n\n\n\nWhile R is a programming language, RStudio is a software (often referred to as an IDE, Integrated Development Environment) that provides R programmers with a neat, easy-to-use interface for coding in R. There are a number of IDEs out there, but RStudio is arguably the best and definitely most popular among R programmers.\nNote: RStudio will not work without R installed, and you won’t particularly enjoy using R without having RStudio installed. Be sure to install both!\n\n\n\n\n\nImage Credit: Manny Gimond | Accessible at https://mgimond.github.io/ES218/R_vs_RStudio.html\n\n\n\n\n\nNew install: To install RStudio, visit https://posit.co/download/rstudio-desktop/. Download the free (“Open Source Edition”) Desktop version for your operating system. You should install the most up-to-date version available that is supported by your operating system.\nUpdate: If you already have RStudio and need to update: Open RStudio, and under ‘Help’ in the top menu, choose ‘Check for updates.’ If you have the most recent release, it will return ‘No update available. You are running the most recent version of RStudio.’ Otherwise, you should follow the instructions to install an updated version.\nOpen RStudio (logo you’ll click on shown below): If upon opening RStudio you are prompted to install Command Line Tools, do it.\n\n\n\n\n\n\n\n\n\n\n\nNote: you may need to install command line tools and XQuartz.\n\nTo install command line tools (if you’re not automatically prompted), run in the Terminal tab in RStudio: xcode-select --install\nVisit xquartz.org to download & install XQuartz\n\n\n\n\n\nQuarto is a scientific publishing tool built on Pandoc that allows R, Python, Julia, and ObservableJS users to create dynamic documents, websites, books and more.\nQuarto is now included with RStudio v2022.07.1+ so no need for a separate download/install if you have the latest version of RStudio! You can find all releases (current, pre, and older releases) on the Quarto website download page, should you want/need to reference them.\n\n\n\nYou should already have git on your device, but let’s check for it anyway.\n\nOpen RStudio\nIn the Terminal, run the following command:\n\n\nwhich git\n\n\nIf after running that you get something that looks like a file path to git on your computer, then you have git installed. For example, that might return something like this (or it could differ a bit): /usr/local/bin/git. If you instead get no response at all, you should download & install git from here: git-scm.com/downloads\n\nAn aside: Is it necessary to have Git installed in your machine for this workshop. GitHub’s Git Guides are a really wonderful resource to start learning about this topic.\n\n\n\n\nInstall the usethis and gitcreds packages in R by running the following in the RStudio Console:\n\n\ninstall.packages(“usethis”)\n\ninstall.packages(\"gitcreds\")\n\nA lot of scary looking red text will show up while this is installing - don’t panic. If you get to the end and see something like below (with no error) it’s installed successfully.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf you don’t already have a GitHub account, go to github.com and create one. Here are helpful considerations for choosing a username: happygitwithr.com/github-acct.html.\n\nOnce you’ve completed these steps you are ready for our workshop on Git and Github",
    "crumbs": [
      "Installing R and Git on Your Computer"
    ]
  },
  {
    "objectID": "r_git_install_guide.html#installation-steps-for-macos",
    "href": "r_git_install_guide.html#installation-steps-for-macos",
    "title": "Installing R and Git on Your Computer",
    "section": "",
    "text": "To install R, visit cloud.r-project.org to download the most recent version for your operating system. The latest release is version 4.5 ([Not] Part in a Rumble, released 2025-10-31). Note: As long as you have version 4.4 or higher you are set for this series.\n\n\n\nWhile R is a programming language, RStudio is a software (often referred to as an IDE, Integrated Development Environment) that provides R programmers with a neat, easy-to-use interface for coding in R. There are a number of IDEs out there, but RStudio is arguably the best and definitely most popular among R programmers.\nNote: RStudio will not work without R installed, and you won’t particularly enjoy using R without having RStudio installed. Be sure to install both!\n\n\n\n\n\nImage Credit: Manny Gimond | Accessible at https://mgimond.github.io/ES218/R_vs_RStudio.html\n\n\n\n\n\nNew install: To install RStudio, visit https://posit.co/download/rstudio-desktop/. Download the free (“Open Source Edition”) Desktop version for your operating system. You should install the most up-to-date version available that is supported by your operating system.\nUpdate: If you already have RStudio and need to update: Open RStudio, and under ‘Help’ in the top menu, choose ‘Check for updates.’ If you have the most recent release, it will return ‘No update available. You are running the most recent version of RStudio.’ Otherwise, you should follow the instructions to install an updated version.\nOpen RStudio (logo you’ll click on shown below): If upon opening RStudio you are prompted to install Command Line Tools, do it.\n\n\n\n\n\n\n\n\n\n\n\nNote: you may need to install command line tools and XQuartz.\n\nTo install command line tools (if you’re not automatically prompted), run in the Terminal tab in RStudio: xcode-select --install\nVisit xquartz.org to download & install XQuartz\n\n\n\n\n\nQuarto is a scientific publishing tool built on Pandoc that allows R, Python, Julia, and ObservableJS users to create dynamic documents, websites, books and more.\nQuarto is now included with RStudio v2022.07.1+ so no need for a separate download/install if you have the latest version of RStudio! You can find all releases (current, pre, and older releases) on the Quarto website download page, should you want/need to reference them.\n\n\n\nYou should already have git on your device, but let’s check for it anyway.\n\nOpen RStudio\nIn the Terminal, run the following command:\n\n\nwhich git\n\n\nIf after running that you get something that looks like a file path to git on your computer, then you have git installed. For example, that might return something like this (or it could differ a bit): /usr/local/bin/git. If you instead get no response at all, you should download & install git from here: git-scm.com/downloads\n\nAn aside: Is it necessary to have Git installed in your machine for this workshop. GitHub’s Git Guides are a really wonderful resource to start learning about this topic.\n\n\n\n\nInstall the usethis and gitcreds packages in R by running the following in the RStudio Console:\n\n\ninstall.packages(“usethis”)\n\ninstall.packages(\"gitcreds\")\n\nA lot of scary looking red text will show up while this is installing - don’t panic. If you get to the end and see something like below (with no error) it’s installed successfully.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf you don’t already have a GitHub account, go to github.com and create one. Here are helpful considerations for choosing a username: happygitwithr.com/github-acct.html.\n\nOnce you’ve completed these steps you are ready for our workshop on Git and Github",
    "crumbs": [
      "Installing R and Git on Your Computer"
    ]
  },
  {
    "objectID": "r_git_install_guide.html#installation-steps-for-windows",
    "href": "r_git_install_guide.html#installation-steps-for-windows",
    "title": "Installing R and Git on Your Computer",
    "section": "2 Installation steps for Windows",
    "text": "2 Installation steps for Windows\n\n2.1 Install or update R\nTo install R, visit cloud.r-project.org to download the most recent version for your operating system. The latest release is version 4.3.2 ( released 2023-10-31).\n\n\n2.2 Install or update RStudio\nWhile R is a programming language, RStudio is a software (often referred to as an IDE, Integrated Development Environment) that provides R programmers with a neat, easy-to-use interface for coding in R. There are a number of IDEs out there, but RStudio is arguably the best and definitely most popular among R programmers.\nNote: RStudio will not work without R installed, and you won’t particularly enjoy using R without having RStudio installed. Be sure to install both!\n\n\n\n\n\nImage Credit: Manny Gimond | Accessible at https://mgimond.github.io/ES218/R_vs_RStudio.html\n\n\n\n\n\nNew install: To install RStudio, visit https://posit.co/download/rstudio-desktop/. Download the free (“Open Source Edition”) Desktop version for your operating system. You should install the most up-to-date version available that is supported by your operating system.\nUpdate: If you already have RStudio and need to update: Open RStudio, and under ‘Help’ in the top menu, choose ‘Check for updates.’ If you have the most recent release, it will return ‘No update available. You are running the most recent version of RStudio.’ Otherwise, you should follow the instructions to install an updated version.\nOpen RStudio (logo you’ll click on shown below): If upon opening RStudio you are prompted to install Command Line Tools, do it.\n\n\n\n\n\n\n\n\n\n\n\n\n2.3 Install Quarto\nQuarto is a scientific publishing tool built on Pandoc that allows R, Python, Julia, and ObservableJS users to create dynamic documents, websites, books and more.\nQuarto is now included with RStudio v2022.07.1+ so no need for a separate download/install if you have the latest version of RStudio! You can find all releases (current, pre, and older releases) on the Quarto website download page, should you want/need to reference them.\n\n\n2.4 Check for git\nYou should already have git on your device, but let’s check for it anyway.\n\nOpen RStudio\nIn the Terminal, run the following command:\n\n\nwhere git\n\n\nIf after running that you get something that looks like a file path to git on your computer, then you have git installed. For example, that might return something like this (or it could differ a bit): /usr/local/bin/git. If you instead get no response at all or something along the lines “git is not installed”, you should download & install git from here: https://gitforwindows.org/.\n\nOnce you have download and installed Git, restart your computer. Then open RStudio and again run:\n\nwhere git\n\nIf you still get a message saying something like “git is not installed”, check out the Troubleshooting section below.\nAn aside: Is it necessary to have Git installed in your machine for this workshop. GitHub’s Git Guides are a really wonderful resource to start learning about this topic.\n\n\n2.5 Install R packages\n\nInstall the usethis and gitcreds packages in R by running the following in the RStudio Console:\n\n\ninstall.packages(\"usethis\")\n\ninstall.packages(\"gitcreds\")\n\nA lot of scary looking red text will show up while this is installing - don’t panic. If you get to the end and see something like below (with no error) it’s installed successfully.\n\n\n\n\n\n\n\n\n\n\n\n2.6 Create a GitHub account\n\nIf you don’t already have a GitHub account, go to github.com and create one. Here are helpful considerations for choosing a username: happygitwithr.com/github-acct.html.\n\nOnce you’ve completed these steps you are ready for our workshop on Git and Github",
    "crumbs": [
      "Installing R and Git on Your Computer"
    ]
  },
  {
    "objectID": "r_git_install_guide.html#troubleshooting",
    "href": "r_git_install_guide.html#troubleshooting",
    "title": "Installing R and Git on Your Computer",
    "section": "3 Troubleshooting",
    "text": "3 Troubleshooting\n\n\n\n\n\n\nWarningIssues installing Git on a Windows\n\n\n\nIf you download Git and the Git commands still not recognized by your computer, check your computer’s PATHS.\nTo do this, follow the instructions in this link on how to set the right PATHS.\nRestart your computer and try running git --version on the terminal. You should get something like git version XX.XX (but with numbers instead of Xs).\nIf you see the git version printed out in your terminal, you are all set",
    "crumbs": [
      "Installing R and Git on Your Computer"
    ]
  },
  {
    "objectID": "slides/r_programming_introduction/slides1_coding_in_console.html#title-slide",
    "href": "slides/r_programming_introduction/slides1_coding_in_console.html#title-slide",
    "title": "coreDUML",
    "section": "",
    "text": "Welcome to R & RStudio\nAn introduction to programming in R\n\nNCEAS Learning Hub"
  },
  {
    "objectID": "slides/r_programming_introduction/slides1_coding_in_console.html#rstudio-ide",
    "href": "slides/r_programming_introduction/slides1_coding_in_console.html#rstudio-ide",
    "title": "coreDUML",
    "section": "",
    "text": "RStudio IDE interface\n\n\n\n\nLet’s take a tour of the RStudio interface!"
  },
  {
    "objectID": "slides/r_programming_introduction/slides1_coding_in_console.html#rstudio-ide2",
    "href": "slides/r_programming_introduction/slides1_coding_in_console.html#rstudio-ide2",
    "title": "coreDUML",
    "section": "",
    "text": "RStudio IDE interface\n\n\n\n\n\nNotice the default panes:\n\nConsole (entire left)\nEnvironment/History (tabbed in upper right)\nFiles/Plots/Packages/Help (tabbed in lower right)\n\nNOTE: New tabs may show up in different contexts (e.g., Git tab)\n\n\n\n\n\nQuick Tip: You can change the default location of the panes, among many other things. More information here."
  },
  {
    "objectID": "slides/r_programming_introduction/slides1_coding_in_console.html#rstudio-console",
    "href": "slides/r_programming_introduction/slides1_coding_in_console.html#rstudio-console",
    "title": "coreDUML",
    "section": "",
    "text": "RStudio IDE interface\n\n\n\n\n\nConsole is where you can directly type R code.\nWhen you start a new session, you’ll see some text that includes the current version of R software installed (yours may not match the image).\n\n\n\n\n\nThere are tabs for Terminal and Background Jobs. Terminal is direct access to your computer’s operating system (not R software)."
  },
  {
    "objectID": "slides/r_programming_introduction/slides1_coding_in_console.html#rstudio-envir",
    "href": "slides/r_programming_introduction/slides1_coding_in_console.html#rstudio-envir",
    "title": "coreDUML",
    "section": "",
    "text": "RStudio IDE interface\n\n\n\n\n\nEnvironment displays information in working memory - “objects” that may be individual values, lists or vectors with multiple values, data frames of tabular data, etc.\nWhen you start a new session, the environment pane should say “Environment is empty.” As you use R to make calculations and store values, you will see objects in this pane.\n\n\n\n\n\nThere is a tab for History and perhaps others. History will show you the sequence of any commands you have typed or executed into R. When writing R scripts, the History tab is not necessary for reproducible science."
  },
  {
    "objectID": "slides/r_programming_introduction/slides1_coding_in_console.html#rstudio-files",
    "href": "slides/r_programming_introduction/slides1_coding_in_console.html#rstudio-files",
    "title": "coreDUML",
    "section": "",
    "text": "RStudio IDE interface\n\n\n\n\n\nFiles displays files and folders on your computer. You can navigate just like you would normally browse on your computer.\n\n\n\n\n\nNote the other tabs in this pane: when you create plots or tables, they will generate in the plots pane. Packages provides information on the packages and versions installed, and Help is provides searchable documentation for those packages and functions. Viewer and Presentation display HTML or other outputs."
  },
  {
    "objectID": "slides/r_programming_introduction/slides1_coding_in_console.html#example-code-slide",
    "href": "slides/r_programming_introduction/slides1_coding_in_console.html#example-code-slide",
    "title": "coreDUML",
    "section": "",
    "text": "Storing values in objects\n\n\nThe assignment operator (&lt;-) creates an “object” by assigning it a name. R will evaluate the expression on the right side, and store that value with the name on the left.\nFor example, assign the result of 3 * 4 and call it “result”. Then we can call the name of the object to use the value in other calculations, and so on.\n\n\nresult &lt;- 3 * 4   ### assign the value\n\nresult            ### retrieve the value\n\n[1] 12"
  },
  {
    "objectID": "slides/r_programming_introduction/slides1_coding_in_console.html#rstudio-envir2",
    "href": "slides/r_programming_introduction/slides1_coding_in_console.html#rstudio-envir2",
    "title": "coreDUML",
    "section": "",
    "text": "RStudio IDE interface\n\n\n\n\n\nNow the Environment pane contains the objects and values we created in our example."
  },
  {
    "objectID": "slides/r_programming_introduction/slides2_coding_in_script.html#title-slide",
    "href": "slides/r_programming_introduction/slides2_coding_in_script.html#title-slide",
    "title": "coreDUML",
    "section": "",
    "text": "Scripts in R and RStudio\nAn introduction to programming in R\n\nNCEAS Learning Hub"
  },
  {
    "objectID": "slides/r_programming_introduction/slides2_coding_in_script.html#script1",
    "href": "slides/r_programming_introduction/slides2_coding_in_script.html#script1",
    "title": "coreDUML",
    "section": "",
    "text": "Creating an R script\n\n\n\n\n\nFrom the “File” menu, select “New File,” then choose “R Script.”\nYou can also create the script from the “new file” button in the Files pane.\nA new pane appears. This is the Source pane, where we write and edit code and documents. This pane is only present if there are files open in the editor.\n\n\n\n\n\nSave the R Script in your script folder, name the file intro_to_programming.R. The name at the top of the Source pane will change from Untitled to the new file name."
  },
  {
    "objectID": "slides/github_introduction/slides1_motivating_example.html#title-slide",
    "href": "slides/github_introduction/slides1_motivating_example.html#title-slide",
    "title": "coreDUML",
    "section": "",
    "text": "Git & GitHub\nA motivating example"
  },
  {
    "objectID": "r_programming_introduction.html",
    "href": "r_programming_introduction.html",
    "title": "3 Working in R & RStudio",
    "section": "",
    "text": "TipLearning Objectives\n\n\n\n\nGet oriented with the RStudio interface\nRun code and basic arithmetic in the Console\nPractice writing code in an R Script\nBe introduced to built-in R functions\nUse the Help pages to look up function documentation",
    "crumbs": [
      "3 Working in R & RStudio"
    ]
  },
  {
    "objectID": "r_programming_introduction.html#welcome-to-r-programming",
    "href": "r_programming_introduction.html#welcome-to-r-programming",
    "title": "3 Working in R & RStudio",
    "section": "1 Welcome to R Programming",
    "text": "1 Welcome to R Programming\n\n\n\nArtwork by Allison Horst\n\n\nIncorporating programming into analysis workflows makes science more efficient and more computationally reproducible. We will use the programming language R, and the accompanying integrated development environment (IDE) RStudio. R is a great language to learn for data-oriented programming because it is widely adopted, user-friendly, and (most importantly) open source.\n\n1.1 What is the difference between R and RStudio?\nImagine you are a chef, and you have to prepare a meal. You’ll need a place to work (a kitchen), you’ll need some tools (pots, pans, a knife, etc.), and you’ll need some ingredients. In this analogy, R is a good chef’s knife - one of the most important tools that you’ll use to accomplish your task.\nAnd if R is your chef’s knife, RStudio is your kitchen. RStudio provides a place to do your work! RStudio makes working with R easier by bringing together other tools for working efficiently - like a file browser, data viewer, help pages, terminal, support, etc. You could learn R without RStudio,\n(and in this analogy, your ingredients are data!)\n\n\n\n\n\n\nWarningR without RStudio?\n\n\n\nJust as you can prepare food without a kitchen, we could learn R without RStudio. RStudio makes it much easier to work with R, just as a well-stocked kitchen makes cooking more fun. We are going to take advantage of the great RStudio support, and learn R and RStudio in conjunction.\n\n\n\n\n\n\n\n\nNoteNew to coding? New to R? No worries!\n\n\n\nLearning R is like learning any new language. It’s an ongoing process, it takes time, you’ll make mistakes, it can be frustrating, but it will be overwhelmingly useful in the long run. We all speak at least one language - no matter how fluent you are, you’ll always be learning, you’ll be trying things in new contexts, learning new words and new phrases.\nYou’ll learn to understand context for programming language just like you learn the context for spoken language. Think about how every language often has a word for the first meal of the day – breakfast in English, desayuno in Spanish. Programming languages also have words (functions) that express specific ideas. There is a way to sort values, search for text patterns, calculate medians, or reshape data. The goal is to expand your expectations so that each goal that you have, there’s likely a function that helps you get there.",
    "crumbs": [
      "3 Working in R & RStudio"
    ]
  },
  {
    "objectID": "r_programming_introduction.html#using-r-within-the-rstudio-ide",
    "href": "r_programming_introduction.html#using-r-within-the-rstudio-ide",
    "title": "3 Working in R & RStudio",
    "section": "2 Using R within the RStudio IDE",
    "text": "2 Using R within the RStudio IDE\nLet’s take a tour of the RStudio interface.\nFull Screen\n\n\n2.1 Objects in R\nLet’s say the value of 12 that we got from running 3 * 4 is a really important value we need to keep. To store information in R, we need to create an object.\nWe can assign a value or expression to an object using the assignment operator, &lt;- (greater than sign and minus sign). All objects in R are created using the assignment operator, following this form: object_name &lt;- value.\n\n\n\n\n\n\nExerciseExercise 1\n\n\n\n\n\n\nCreate an object!\nAssign your favorite number to an object called fave_num. Then, create an object called fave_squared and assign the square of fave_num (use the superscript, like 5^2), and inspect the object.\n\n\n\n\n\n\nAnswerAnswer\n\n\n\n\n\n\n\n### think of this code as someone saying \"fave_num gets 42\".\nfave_num &lt;- 42\n\n### and then square it\nfave_squared &lt;- fave_num^2\nfave_squared\n\n[1] 1764\n\n\nNotice how after creating the fave_num object, R doesn’t print anything. However, we know our code worked because we see the object, and the value we wanted to store is now visible in our Global Environment. We can force R to print the value of the object by calling the object name (aka typing it out) or by using parentheses.\n\n### printing the object by calling the object name\nfave_squared\n\n[1] 1764\n\n### printing the object by wrapping the assignment syntax in parentheses\n(fave_squared &lt;- fave_num^2)\n\n[1] 1764\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipQuick navigation in the console\n\n\n\nWhen you begin typing, RStudio will suggest autocompletions that you can select by hitting tab, then return.\nIn the Console, use the up and down arrow keys to call your command history, which shows the most recent commands first.\n\n\n\n\n2.2 Naming Things\nWhen naming objects, variables, observations, or data frames, make them:\n\nMeaningful\n\nPick names that are specific to the data, experiment, or project. Their interpretation should be intuitive - they shouldn’t be so generic or vague that the user needs a glossary to know what they contain.\nBad Examples: File-1.xlsx, indicator1, indicator2, ExperimentA.R, ExperimentB.R\nBetter Examples: taco_nutrients.csv, nc_demographics, mice_1a_mass, rachel_carson_spatial.shp\n\nConsistent\n\nKeep names perfectly identical for identical value entries (e.g. “burrito-32” and “Burrito 32” are completely different things to R)\nBe consistent across data frames. Your life will be easier if you have year called “year” in both sets, instead of “Year” and “YEAR” and “Year_New”.\nUse logical suffixes (if necessary), consistently formatted. Like: temp_water_surface, temp_water_sub, temp_water_bottom\n\nConcise\n\nBalance meaningfulness with conciseness\nBetter to be descriptive than not know what a variable is (especially with tab completion)\nLonger names = tedious coding, but less effort to look through metadata for column/identifier names (or risk of mis-remembering…)\nBad examples: ‘first dive temp readings Celsius’, greatblueheron_observations_2019_09_20, “Cori final figures version 3.xlsx”\nBetter examples: beaufort_sst, UsTotalPop, PercCover\n\nCode and coder-friendly\n\nAvoid punctuation (%, !, ~, (, ), #) in names - more challenging to type and can mean things in code that you don’t want it to (or break it)\nAvoid spaces (makes coding much more difficult)\nAvoid starting object names with numbers (but could be useful for file names in sequence)\nPick and be consistent with a choice of case\n\n\n\n2.2.1 Case conventions\nA clear, consistent naming convention improves readability and reduces cognitive load. Choosing one is a personal preference.\nFor the object fave_num, we used an underscore to separate the object name. This naming convention is called lowercase snake case - it is common in data science because it’s easy to scan, works well across operating systems, and avoids ambiguity.\n\n\n\n\n\n\n\nsnake_case\neasy to scan, works well across OS\n\n\ncamelCase\ncompact but less readable\n\n\nUpperCamelCase (also called PascalCase)\noften used to signal a different type of object (e.g. functions)\n\n\nkebab-case\nnot good for objects because R treats a hyphen as a minus sign\n(but works nicely for file names)\n\n\nSCREAMING_SNAKE_CASE\ncase is a personal preference so you can absolutely pick what you want as long as you are consistent…",
    "crumbs": [
      "3 Working in R & RStudio"
    ]
  },
  {
    "objectID": "r_programming_introduction.html#running-code-in-an-r-script",
    "href": "r_programming_introduction.html#running-code-in-an-r-script",
    "title": "3 Working in R & RStudio",
    "section": "3 Running code in an R Script",
    "text": "3 Running code in an R Script\nWe’ve been typing code in the Console, let’s try running code in an R Script. A script is a plain text file that RStudio uses by sending the selected lines to the Console, just as if you had typed them yourself.\nFull Screen\n\n\n\n\n\n\n\nExerciseExercise 2\n\n\n\n\n\n\nCreate a vector!\nCreate a vector with the values 18.1, 8.9, 11.3, 11.2, and 15.7, representing tree heights in meters, and assign it an appropriate name. Convert these heights to feet (1 meter = 3.28 feet) and store the result in a second object.\nAs a bonus, calculate the average tree height. Hint: look at the mean function! Typing ?mean in the console will show you the help page for this function.e\n\n\n\n\n\n\nAnswerAnswer\n\n\n\n\n\n\n\n### Height of trees in meters\ntree_h_m &lt;- c(18.1, 8.9, 11.3, 11.2, 15.7)\n\nm_to_ft &lt;- 3.28  ### meters to feet conversion ratio\n\n### Height of trees in feet\ntree_h_ft &lt;- tree_h_m * m_to_ft\n\n### Mean height of trees, in feet\nmean(tree_h_ft)\n\n[1] 42.7712",
    "crumbs": [
      "3 Working in R & RStudio"
    ]
  },
  {
    "objectID": "r_programming_introduction.html#data-types-and-structures-in-r",
    "href": "r_programming_introduction.html#data-types-and-structures-in-r",
    "title": "3 Working in R & RStudio",
    "section": "4 Data types and structures in R",
    "text": "4 Data types and structures in R\nWe’ve been using numeric data types, but R also works with text. Creating a character object requires quotes:\n\nscience_rocks &lt;- \"yes it does!\"\n\n\n\n\n\n\n\nExerciseExercise 3\n\n\n\n\n\n\nTry running the following lines in your script or console:\n\n\"Hello world!\" * 5\n\n\"7\" * 5\n\n7 * 5\n\nWhat happened? What do you see in the Console?\n\n\n\n\nThese examples show how R treats different data types. Only the numeric expression produces a calculation. Character strings can’t be multiplied because their operations differ from those defined for numbers.\nEvery object in R has a class, and valid operations depend on that class. Numbers support arithmetic; strings support text manipulation, which you can extend with packages such as stringr and tidytext packages.\nFull Screen\n\n\n\n\n\n\n\nExerciseExercise 4 - Accessing data in a data frame\n\n\n\n\n\n\nWorking with data frames is an important skill for data science in R. There are some built-in datasets in R, including sample data frames that we can work with. Let’s access the built-in mtcars data frame, a set of attributes of various cars from Motor Trends 1974.\n\ndata(mtcars) ### loads a built-in dataset\nhead(mtcars) ### look at the first few rows\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n\nFigure out at least 3 ways to access the horsepower hp of a Datsun 710.\n\n\n\n\n\n\nAnswerAnswer\n\n\n\n\n\n\nHere are a few ways that would work:\n\n#|eval: false\n### choose the 3rd row, 4th column:\nmtcars[3, 4]\n\n[1] 93\n\n### Put the hp column into a vector, then choose\n### the 3rd element of the vector (3 ways):\nx &lt;- mtcars$hp\nx[3]           \n\n[1] 93\n\ny &lt;- mtcars[['hp']]\ny[3]\n\n[1] 93\n\nz &lt;- mtcars[ , 4]\nz[3]\n\n[1] 93\n\n### note, you can chain these:\nmtcars$hp[3]\n\n[1] 93\n\n### Similarly, select just the Datsun 710 row (3),\n### then choose the hp out of that\nx &lt;- mtcars[3, ]\nx$hp\n\n[1] 93\n\n### Use row names and column names:\nmtcars['Datsun 710', 'hp']\n\n[1] 93\n\n\nWe’ll learn more ways later, with the powerful and popular tidyverse package. Note that choosing by row number and column number is a little risky - what if someone reorders the rows or columns and doesn’t tell you? So choosing by name where possible, or filtering using logical tests, is generally preferable!",
    "crumbs": [
      "3 Working in R & RStudio"
    ]
  },
  {
    "objectID": "r_programming_introduction.html#r-functions",
    "href": "r_programming_introduction.html#r-functions",
    "title": "3 Working in R & RStudio",
    "section": "5 R Functions",
    "text": "5 R Functions\nIn R, an object is a noun while a function is a verb - functions do all our data science work for us.\nFull Screen\n\n\n5.1 Examples\nCreate a vector to store the noon temperature (in Celsius) in Beaufort for three consecutive summer days:\n\ntemp_c &lt;- c(27, 29, 31)\n\n\n\n\n\n\n\nExerciseExercise 5\n\n\n\n\n\n\nUse the mean() function to calculate the mean temperature\nUse the Help page for mean() (?mean) to see what the function expects: it computes the mean of a numeric vector, and its only required argument is x. Using it here:\n\n\n\n\n\n\nAnswerAnswer\n\n\n\n\n\n\n\nmean(x = temp_c)\n\n[1] 29\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExerciseExercise 6\n\n\n\n\n\n\nSave the mean to an object called mean_temp_c\n\n\n\n\n\n\nAnswerAnswer\n\n\n\n\n\n\n\n### saving the mean using the assignment operator `&lt;-`\nmean_temp_c &lt;- mean(x = temp_c)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExerciseExercise 7\n\n\n\n\n\n\nEarlier, we created a vector of tree heights in meters (tree_h_m). Use mean() again and store it in a new object called mean_h_m.\n\nmean_height_m &lt;- mean(tree_h_m)\n\nAfter ten years, each tree has grown 3 meters. Update the vector:\n\ntree_h_m &lt;- tree_h_m + 3 ### note, this adds 3 to each element!\n\nNow, call mean_height_m in the console or take a look at your Global Environment. Is that the value you expected? Why or why not?\n\n\n\n\n\n\nAnswerAnswer\n\n\n\n\n\n\nCalling mean_h_m now shows the original value. Object assignment in R is independent: updating tree_h_m does not update mean_h_m unless you recalculate it.\n\n\n\n\n\n\n\n\nThis provides an important concept: R scripts run from top to bottom. When editing a script, values depend on the order in which the lines are executed. Clearing the environment and running the script from start to finish is the best way to ensure the results reflect the full sequence of code.",
    "crumbs": [
      "3 Working in R & RStudio"
    ]
  },
  {
    "objectID": "r_programming_introduction.html#reading-and-working-with-data-frames",
    "href": "r_programming_introduction.html#reading-and-working-with-data-frames",
    "title": "3 Working in R & RStudio",
    "section": "6 Reading and working with data frames",
    "text": "6 Reading and working with data frames\n\n6.1 Use the read.csv() function to read a file into R\nWe’ve assigned values to objects and used functions, but now we’ll bring in real data. read.csv() is a function that does exactly what it promises: it reads a CSV file into R.\nSince this is our first time using it, start with the Help page (?read.csv). It’s long because the function has many optional arguments, but the key one is the first: you need to tell R which file to read. Let’s get a file!\n\n\n\n\n\n\nTipDownload a file from the Arctic Data Center\n\n\n\n\nNavigate to this dataset by Craig Tweedie that is published on the Arctic Data Center. Craig Tweedie. 2009. North Pole Environmental Observatory Bottle Chemistry. Arctic Data Center. doi:10.18739/A25T3FZ8X.\nDownload BGchem2008data.csv by clicking the “download” button next to the file (cloud + arrow). Save it in a folder called data in the project.\nConfirm the file is in data by checking the Files pane.\n\n\n\nNow tell read.csv() where to find the file. The Help page shows the file argument, which takes a path. In R, you can either use absolute paths (which will start with your home directory ~/) or paths relative to your current working directory. RStudio has some great auto-complete capabilities when using relative paths, so we will go that route.\nIf your working directory is your project (training_{NAME}) and the CSV is in data, your import looks like this:\n\n# reading in data using relative paths\nbg_chem_dat &lt;- read.csv(\"data/BGchem2008data.csv\")\n\nThis creates a data frame called bg_chem_dat. Check that it loaded by looking in the environment pane.\n\n\n\n\n\n\nTipOptional Arguments\n\n\n\nThe Help page for read.csv() lists many arguments we didn’t use. Some are optional; some are required. Optional arguments appear as name = value, where the value shown is the default. If you don’t specify that argument, the function uses the default. For read.csv(), header = TRUE is a typical example.\nRequired arguments appear without a value. For read.csv(), the only required argument is file.\n\n\nR can match arguments by name or by position. In our earlier call, we didn’t specify file = because file is the first argument, and R assigns the first value to it automatically. The equivalent explicit call would be:\n\nbg_chem_dat &lt;- read.csv(file = \"data/BGchem2008data.csv\")\n\nTo adjust another argument, we need to name it, because the second argument in read.csv() is header. For example, many people set stringsAsFactors like this:\n\n# relative file path\nbg_chem_dat &lt;- read.csv(\"data/BGchem2008data.csv\", stringsAsFactors = FALSE)\n\n\n\n\n\n\n\nTipQuick Tip\n\n\n\nWith familiar functions, it’s common to omit names for the first one or two arguments. For less familiar functions, naming every argument makes your code more readable for collaborators and your future self.\n\n\n\n\n6.2 Working with data frames in R\nA data.frame stores tabular data: columns represent variables, and rows represent observations. When you used read.csv(), the result was a data.frame saved as bg_chem_dat. Explore it a few ways:\n\nClick on bg_chem_dat in the environment pane\nClick on the arrow next to bg_chem_dat in the environment pane\nRun head(bg_chem_dat) in the Console\nRun View(bg_chem_dat) in the Console\n\nNow examine specific columns and try a few simple calculations:\n\nhead(bg_chem_dat$Date)\n\nmean_temp &lt;- mean(bg_chem_dat$CTD_Temperature)\n\n\n\n\n\n\n\nTipOther ways to load tablular data\n\n\n\nBase R’s read.csv() is common, but many workflows use other import functions that also produce data frames:\n\nreadr::read_csv() from the handles csv files quickly and parses types (including dates) more reliably. (try: bg_chem_dat &lt;- readr::read_csv(\"data/BGchem2008data.csv\"))\nreadxl::read_excel() reads Excel files.\ngooglesheets4::read_sheet() reads directly from Google Sheets.",
    "crumbs": [
      "3 Working in R & RStudio"
    ]
  },
  {
    "objectID": "r_programming_introduction.html#logical-operators-and-expressions",
    "href": "r_programming_introduction.html#logical-operators-and-expressions",
    "title": "3 Working in R & RStudio",
    "section": "7 Logical operators and expressions",
    "text": "7 Logical operators and expressions\nWe can ask questions about an object using logical operators and expressions. Let’s ask some “questions” about the tree_h_m object we made.\n\n== means ‘is equal to’\n!= means ‘is not equal to’\n&lt; means ‘is less than’\n&gt; means ‘is greater than’\n&lt;= means ‘is less than or equal to’\n&gt;= means ‘is greater than or equal to’\n\nR will apply the logical test to each element of a vector and tell you the result as TRUE or FALSE.\n\n# examples using logical operators and expressions\ntree_h_m == 8.9\n\n[1] FALSE FALSE FALSE FALSE FALSE\n\ntree_h_m &gt;= 14\n\n[1]  TRUE FALSE  TRUE  TRUE  TRUE\n\ntree_h_m != 11.3\n\n[1] TRUE TRUE TRUE TRUE TRUE",
    "crumbs": [
      "3 Working in R & RStudio"
    ]
  },
  {
    "objectID": "r_programming_introduction.html#clearing-the-environment",
    "href": "r_programming_introduction.html#clearing-the-environment",
    "title": "3 Working in R & RStudio",
    "section": "8 Clearing the environment",
    "text": "8 Clearing the environment\nTake a look at the objects in your Environment (Workspace) in the upper right pane. The Workspace is where user-defined objects accumulate. There are a few useful commands for getting information about your Environment, which make it easier for you to reference your objects when your Environment gets filled with many, many objects.\n\nYou can get a listing of these objects with a couple of different R functions:\n\nobjects()\n\n [1] \"fave_num\"      \"fave_squared\"  \"m_to_ft\"       \"mean_height_m\"\n [5] \"mean_temp_c\"   \"mtcars\"        \"science_rocks\" \"temp_c\"       \n [9] \"tree_h_ft\"     \"tree_h_m\"      \"x\"             \"y\"            \n[13] \"z\"            \n\nls()\n\n [1] \"fave_num\"      \"fave_squared\"  \"m_to_ft\"       \"mean_height_m\"\n [5] \"mean_temp_c\"   \"mtcars\"        \"science_rocks\" \"temp_c\"       \n [9] \"tree_h_ft\"     \"tree_h_m\"      \"x\"             \"y\"            \n[13] \"z\"            \n\n\nIf you want to remove the object named tree_h_m, you can do this:\n\nrm(tree_h_m)\n\nTo remove everything (or click the Broom icon in the Environment pane):\n\nrm(list = ls())\n\n\n8.0.1 Quick Tip\nIt’s good practice to clear your environment. Over time your Global Environmental will fill up with many objects, and this can result in unexpected errors or objects being overridden with unexpected values. Also it’s difficult to read / reference your environment when it’s cluttered!",
    "crumbs": [
      "3 Working in R & RStudio"
    ]
  },
  {
    "objectID": "r_programming_introduction.html#save-workspace-image-to-.rdata",
    "href": "r_programming_introduction.html#save-workspace-image-to-.rdata",
    "title": "3 Working in R & RStudio",
    "section": "9 Save Workspace Image to .RData?",
    "text": "9 Save Workspace Image to .RData?\n\nDON’T SAVE\nWhen ever you close or switch projects you will be promped with the question: Do you want to save your workspace image to /“current-project”/ .RData?\nRStudio by default wants to save the state of your environment (the objects you have in your environment pane) into the RData file so that when you open the project again you have the same environment. However, as we discussed above, it is good practice to constantly clear and clean your environment. It is generally NOT a good practice to rely on the state of your environment for your script to run and work. If you are coding reproducibly, your code should be able to reproduce the state of your environment (all the necessary objects) every time you run it. It is much better to rely on your code recreating the environment than saving the workspace status.\nTo make sure you’re always working reproducibly, change the Global Options configuration for the default to be NEVER SAVE MY WORKSPACE. Go to Tools &gt; Global Options. Under the General menu, select Never next to “Save workspace to .RData on exit” (and uncheck “Restore .RData into workspace at startup”). This way you won’t get asked every time you close a project, instead RStudio knows not to save.\n :::::::::::::::::::::::::::",
    "crumbs": [
      "3 Working in R & RStudio"
    ]
  }
]